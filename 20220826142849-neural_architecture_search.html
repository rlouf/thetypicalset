<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-12-01 Thu 10:34 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Neural Architecture Search</title>
<meta name="author" content="RÃ©mi Louf" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="style.css" /><script data-goatcounter="https://thetypicalset.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Neural Architecture Search</h1>

<div id="outline-container-org5a9cf55" class="outline-2">
<h2 id="org5a9cf55">References</h2>
<div class="outline-text-2" id="text-org5a9cf55">
<ul class="org-ul">
<li><p>
Neural Architecture Search with Reinforcement Learning (<a target='_blank' rel='noopener noreferrer' class='external' href="https://arxiv.org/abs/1611.01578">ArxiV</a>)
</p>

<p>
<b>This is the one we should get inspiration from if we were to implement this idea with <code>Aesara</code></b>
</p></li>

<li><p>
Designing Neural Network Architectures using Reinforcement Learning (2017) (<a target='_blank' rel='noopener noreferrer' class='external' href="https://arxiv.org/abs/1611.02167">ArXiv</a>)
</p>


<div id="org9615b02" class="figure">
<p><img src="img/nas-bower2017-statespace.png" alt="nas-bower2017-statespace.png" />
</p>
<p><span class="figure-number">Figure 1: </span>State space of the model search</p>
</div>

<p>
These state space descriptions can be easily written in the form of <a href="20220804135950-minikanren.html#ID-f4cf39be-6c6a-4a9d-804a-3879a98177bc">miniKanren</a> constraints and rewrite rules.
</p></li>

<li><p>
A Genetic Programming Approach to Designing Convolutional Neural Network Architectures (2017) (<a target='_blank' rel='noopener noreferrer' class='external' href="https://arxiv.org/abs/1704.00764">ArXiv</a>) (<a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/sg-nm/cgp-cnn">Github</a>)
</p>

<blockquote>
<p>
The convolutional neural network (CNN), which is one of the deep learning models, has seen much success in a variety of computer vision tasks. However, designing CNN architectures still requires expert knowledge and a lot of trial and error. In this paper, we attempt to automatically construct CNN architectures for an image classification task based on Cartesian genetic programming (CGP). In our method, we adopt highly functional modules, such as convolutional blocks and tensor concatenation, as the node functions in CGP. The CNN structure and connectivity represented by the CGP encoding method are optimized to maximize the validation accuracy. To evaluate the proposed method, we constructed a CNN architecture for the image classification task with the CIFAR-10 dataset. The experimental result shows that the proposed method can be used to automatically find the competitive CNN architecture compared with state-of-the-art models.
</p>
</blockquote></li>

<li>Accelerating Neural Archistecture Search using Performance Prediction (<a target='_blank' rel='noopener noreferrer' class='external' href="https://arxiv.org/abs/1705.10823">ArXiv</a>)</li>

<li><p>
Neural Architecture Search: A survey (<a target='_blank' rel='noopener noreferrer' class='external' href="https://arxiv.org/abs/1808.05377">ArXiv</a>)
</p>

<blockquote>
<p>
Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.
</p>
</blockquote></li>

<li><p>
A Survey on Neural Architecture Search (<a target='_blank' rel='noopener noreferrer' class='external' href="https://arxiv.org/abs/1905.01392">ArXiv</a>)
</p>

<blockquote>
<p>
The growing interest in both the automation of machine learning and deep learning has inevitably led to the development of a wide variety of automated methods for neural architecture search. The choice of the network architecture has proven to be critical, and many advances in deep learning spring from its immediate improvements. However, deep learning techniques are computationally intensive and their application requires a high level of domain knowledge. Therefore, even partial automation of this process helps to make deep learning more accessible to both researchers and practitioners. With this survey, we provide a formalism which unifies and categorizes the landscape of existing methods along with a detailed analysis that compares and contrasts the different approaches. We achieve this via a comprehensive discussion of the commonly adopted architecture search spaces and architecture optimization algorithms based on principles of reinforcement learning and evolutionary algorithms along with approaches that incorporate surrogate and one-shot models. Additionally, we address the new research directions which include constrained and multi-objective architecture search as well as automated data augmentation, optimizer and activation function search.
</p>
</blockquote></li>
</ul>
</div>
</div>

<div id="outline-container-org5d4e889" class="outline-2">
<h2 id="org5d4e889">Links to this note</h2>
<div class="outline-text-2" id="text-org5d4e889">
<ul class="org-ul">
<li><a href="./20220826141720-automatic_model_selection_with_aesara_rewrites.html">Automatic model selection with Aesara rewrites</a></li>
</ul>
</div>
</div>
</div>
</body>
</html>