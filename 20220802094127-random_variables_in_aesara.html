<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-12-20 Tue 10:30 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Random Variables in Aesara</title>
<meta name="author" content="RÃ©mi Louf" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="style.css" /><script data-goatcounter="https://thetypicalset.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Random Variables in Aesara</h1>
<ul class="org-ul">
<li><code>RandomGenerator</code></li>
<li><code>RandomState</code></li>
<li><code>RandomStream</code></li>
</ul>

<div id="outline-container-org4106eb9" class="outline-2">
<h2 id="org4106eb9">AeP: PRNG and <code>RandomVariable</code> representation in Aesara</h2>
<div class="outline-text-2" id="text-org4106eb9">
</div>
<div id="outline-container-orga2c892b" class="outline-3">
<h3 id="orga2c892b">Summary</h3>
<div class="outline-text-3" id="text-orga2c892b">
<p>
I propose a new approach to represent <code>RandomVariable</code> and PRNG states in Aesara's IR, based on the design of splittable PRNGs. The representation introduces minimal change to the existing <code>RandomVariable</code> interface while being more expressive. It should be easy to transpile to Aesara's current compilation target, and is compatible with the higher-level <code>RandomStream</code> interface.
</p>
</div>
</div>

<div id="outline-container-orgdace636" class="outline-3">
<h3 id="orgdace636">References</h3>
<div class="outline-text-3" id="text-orgdace636">
<p>
On counter-based PRNGs:
</p>
<ul class="org-ul">
<li><a target='_blank' rel='noopener noreferrer' class='external' href="http://www.thesalmons.org/john/random123/papers/random123sc11.pdf">Parallel Random Numbers: As easy as 1, 2, 3</a> (2011)</li>
</ul>

<p>
On splittable PRNG design for functional programs:
</p>
<ul class="org-ul">
<li><a target='_blank' rel='noopener noreferrer' class='external' href="https://www.cambridge.org/core/journals/journal-of-functional-programming/article/distributed-random-number-generation/6D10F1D0A2FB7E66D5F746F6D0822D78">Distributed Random Number Generation</a> (2008)</li>
<li><a target='_blank' rel='noopener noreferrer' class='external' href="https://publications.lib.chalmers.se/records/fulltext/183348/local_183348.pdf">Splittable PRNGs Using Cryptographic Hashing</a> (2013)</li>
</ul>
</div>
</div>

<div id="outline-container-orgfa24137" class="outline-3">
<h3 id="orgfa24137">Desiderata</h3>
<div class="outline-text-3" id="text-orgfa24137">
<p>
A good PRNG design satisfies the following conditions:
</p>
<ol class="org-ol">
<li>It is expressive: the behavior of the system is predictable by the caller, and allows them to expression any probabilistic program;</li>
<li>It makes it possible to build reproducible programs ("seeding");</li>
<li>It is embedded in in Aesara's IR;</li>
<li>It can be manipulated by Aesara's rewrite system;</li>
<li>It can be easily transpiled to current backends;</li>
<li>It enables vectorization with generalized universal functions;</li>
</ol>
</div>
</div>

<div id="outline-container-orga7f44b7" class="outline-3">
<h3 id="orga7f44b7">Motivation behind this proposal</h3>
<div class="outline-text-3" id="text-orga7f44b7">
<p>
This proposal is motivated by two issues that illustrate the shortcomings of the current representation of <code>RandomVariable</code>\s and PRNG states in Aesara:
</p>

<ul class="org-ul">
<li>In <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aesara/pull/1036">#1036</a> the use of <code>default_output</code> to hide the PRNG state from the user is causing multiple headaches in the etuplization of <code>RandomVariable</code>\s and unification/reification of expressions with <code>RandomVariable</code>\s. This is the only <code>Op</code> in Aesara that makes use of this property, and to "special-casing" the etuplization logic for <code>RandomVariable</code>\s often appeared as the easiest solution.</li>
<li><p>
In <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aemcmc/pull/66#issuecomment-1258471312">#66</a> in AeMCMC, expressing expansions like the following convolution of two normal variables is overly complex:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">from</span> etuples <span style="color: #F0DFAF; font-weight: bold;">import</span> etuple
<span style="color: #F0DFAF; font-weight: bold;">from</span> kanren <span style="color: #F0DFAF; font-weight: bold;">import</span> var

<span style="color: #DFAF8F;">mu_x</span>, <span style="color: #DFAF8F;">mu_y</span>, <span style="color: #DFAF8F;">sigma2_x</span>, <span style="color: #DFAF8F;">sigma2_y</span> = var(), var(), var(), var()

<span style="color: #DFAF8F;">rng</span>, <span style="color: #DFAF8F;">size</span>, <span style="color: #DFAF8F;">dtype</span> = var(), var(), var()
<span style="color: #DFAF8F;">X_et</span> = etuple(
    etuplize(at.random.normal),
    rng,
    size,
    dtype,
    etuple(
        etuplize(at.add),
        mu_x,
        mu_y
    ),
    etuple(
        etuplize(at.add),
        sigma2_x,
        sigma2_y,
    )
)

<span style="color: #DFAF8F;">rng_x</span>, <span style="color: #DFAF8F;">size_x</span>, <span style="color: #DFAF8F;">dtype_x</span> = var(), var(), var()
<span style="color: #DFAF8F;">rng_y</span>, <span style="color: #DFAF8F;">size_y</span>, <span style="color: #DFAF8F;">dtype_y</span> = var(), var(), var()
<span style="color: #DFAF8F;">Y_et</span> = etuple(
    etuplize(at.add),
    etuple(
        etuplize(at.random.normal),
        rng_x,
        size_x,
        dtype_x,
        mu_x,
        sigma2_x
    ),
    etuple(
        etuplize(at.random.normal),
        rng_y,
        size_y,
        dtype_y,
        mu_y,
        sigma2_y
    )
)
</pre>
</div>

<p>
It is indeed not clear what the values of <code>rng_x</code> and <code>rng_y</code> should be given the value of <code>rng</code>. A few other application-related shortcomings of the current representation will be given below.
</p></li>
</ul>
</div>
</div>

<div id="outline-container-org500ddb4" class="outline-3">
<h3 id="org500ddb4">Proposal</h3>
<div class="outline-text-3" id="text-org500ddb4">
<p>
In the following we focus on <i>the symbolic representation of random variables and PRNG states in Aesara's IR</i>. We leave discussions about compilation targets and solution to the previous issues for the end.
</p>

<p>
If we represent the internal state of the PRNG by the type <code>RandState</code> (short for <code>RandomStateType</code>), the current design of <code>RandomVariable</code>\s can be summarized by the following simplified signature:
</p>

<div class="org-src-container">
<pre class="src src-haskell">RandomVariable :: RandState -&gt; (RandState, TensorVariable)
</pre>
</div>

<p>
In other words, <code>RandomVariable</code>\s are responsible for <b>both</b> advancing the state of the PRNG, and producing a random value. This double responsibility is what creates graph dependencies between nodes that have otherwise no data dependency. The following snippet illustrates this:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara
<span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">rng</span> = at.random.<span style="color: #DCDCCC; font-weight: bold;">type</span>.RandomStateType()(<span style="color: #CC9393;">'rng'</span>)

<span style="color: #DFAF8F;">rng_x</span>, <span style="color: #DFAF8F;">x_rv</span> = at.random.normal(0, 1, rng=rng, name=<span style="color: #CC9393;">'x'</span>).owner.outputs
<span style="color: #DFAF8F;">rng_y</span>, <span style="color: #DFAF8F;">y_rv</span> = at.random.normal(0, 1, rng=rng_x, name=<span style="color: #CC9393;">'y'</span>).owner.outputs
<span style="color: #DFAF8F;">z_rv</span> = at.random.normal(0, 1, rng=rng_y, name=<span style="color: #CC9393;">'z'</span>)
<span style="color: #DFAF8F;">w_at</span> = x_rv + y_rv + z_rv

aesara.dprint(w_at)
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Elemwise{add,no_inplace} [id A]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">|Elemwise{add,no_inplace} [id B]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">| |normal_rv{0, (0, 0), floatX, False}.1 [id C] 'x'</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">| | |rng [id D]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">| | |TensorConstant{[]} [id E]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">| | |TensorConstant{11} [id F]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">| | |TensorConstant{0} [id G]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">| | |TensorConstant{1} [id H]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">| |normal_rv{0, (0, 0), floatX, False}.1 [id I] 'y'</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">|   |normal_rv{0, (0, 0), floatX, False}.0 [id C]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">|   |TensorConstant{[]} [id J]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">|   |TensorConstant{11} [id K]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">|   |TensorConstant{0} [id L]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">|   |TensorConstant{1} [id M]</span>
<span style="color: #5F7F5F;">#  </span><span style="color: #7F9F7F;">|normal_rv{0, (0, 0), floatX, False}.1 [id N] 'z'</span>
<span style="color: #5F7F5F;">#    </span><span style="color: #7F9F7F;">|normal_rv{0, (0, 0), floatX, False}.0 [id I]</span>
<span style="color: #5F7F5F;">#    </span><span style="color: #7F9F7F;">|TensorConstant{[]} [id O]</span>
<span style="color: #5F7F5F;">#    </span><span style="color: #7F9F7F;">|TensorConstant{11} [id P]</span>
<span style="color: #5F7F5F;">#    </span><span style="color: #7F9F7F;">|TensorConstant{0} [id Q]</span>
<span style="color: #5F7F5F;">#    </span><span style="color: #7F9F7F;">|TensorConstant{1} [id R]</span>
</pre>
</div>

<p>
As we can see in the graph representation, <code>rng_x</code> (id C) is being used as an input to <code>y</code> and <code>rng_y</code> (id I) is being used as an input to <code>z</code>. There is however no data dependency between <code>x</code>, <code>y</code> or <code>z</code>. The intuition that they should not be linked is probably what led to "hiding" these PRNG state outputs so they are not re-used, and the <code>RandomStream</code> interface.
</p>

<p>
Creating spurious sequential dependencies by threading PRNG states is indeed unsatisfactory from a representation perspective, and unnecessarily complicates the rewrites. It is also problematic for two other reasons:
</p>

<ul class="org-ul">
<li><i>Parallelization and Vectorization:</i> Using random variables in user-defined generalized universal functions is going to require a lot of compiler magic to make sure that the random state is updated properly, and the behavior will be completely opaque to the user;</li>
<li>The fact that callers cannot be intentional about what they do with the random state is limiting. This can be necessary in pratical applications, for instance to implement <a target='_blank' rel='noopener noreferrer' class='external' href="https://statisfaction.wordpress.com/2017/09/17/unbiased-hamiltonian-monte-carlo-with-couplings/">coupled sampling algorithms</a> in which two algorithms share the same random state.</li>
</ul>

<p>
A natural idea is to simplify the design of <code>RandomVariable</code>\s so that it is only responsible for one thing: generating a random value from a PRNG state. The <code>Op</code> thus creates an <code>Apply</code> node that takes a <code>RandState</code> (using the above notation) as input and outputs a (random) <code>Variable</code>:
</p>

<div class="org-src-container">
<pre class="src src-haskell">RandomVariable :: RandState -&gt; Variable
</pre>
</div>

<p>
Providing a <code>RandState</code> to a <code>RandomVariable</code> needs to intentional, and this must be reflected in the user interface. We thus make <code>rng</code> an explicit input of the <code>RandomVariable</code>'s <code>__call__</code> method. This way a user can write:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">rng_x, rng_y and rng_z are created before that.</span>
<span style="color: #DFAF8F;">x_rv</span> = at.random.normal(rng_x, 0, 1)
<span style="color: #DFAF8F;">y_rv</span> = at.random.normal(rng_y, 0, 1)
<span style="color: #DFAF8F;">z_rv</span> = at.random.normal(rng_z, 0, 1)
</pre>
</div>

<p>
Or, if they want the PRNG state to be shared (silly example, but a legitimate need):
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">rng_x, rng_y and rng_z are created before that.</span>
<span style="color: #DFAF8F;">x_rv</span> = at.random.normal(rng_x, 0, 1)
<span style="color: #DFAF8F;">y_rv</span> = at.random.normal(rng_x, 0, 1)
<span style="color: #DFAF8F;">z_rv</span> = at.random.normal(rng_x, 0, 1)
</pre>
</div>

<p>
This interface presupposes the existence of two operators. First, to build reproducible programs, we need an operator that creates a <code>RandState</code> from a seed, which can be the constructor of <code>RandState</code> itself:
</p>

<div class="org-src-container">
<pre class="src src-haskell">RandState.__init__ :: Seed -&gt; RandState
</pre>
</div>

<p>
And then, we need another operator that creates an updated <code>RandomState</code> from a <code>RandomState</code>, so that <code>RandomVariable</code>\s created with these two different states would output different numbers. Let's call it <code>next</code>:
</p>

<div class="org-src-container">
<pre class="src src-haskell">next :: RandomState -&gt; RandomState
</pre>
</div>

<p>
We can thus fill in the blanks in the previous code examples:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">rng</span> = at.random.RandState(0)
<span style="color: #DFAF8F;">rng_y</span> = at.random.<span style="color: #DCDCCC; font-weight: bold;">next</span>(rng_x)
<span style="color: #DFAF8F;">rng_z</span> = at.random.<span style="color: #DCDCCC; font-weight: bold;">next</span>(rng_y)

<span style="color: #DFAF8F;">x_rv</span> = at.random.normal(rng_x, 0, 1)
<span style="color: #DFAF8F;">y_rv</span> = at.random.normal(rng_y, 0, 1)
<span style="color: #DFAF8F;">z_rv</span> = at.random.normal(rng_z, 0, 1)

<span style="color: #DFAF8F;">w_at</span> = x_rv + y_rv + z_rv
</pre>
</div>

<p>
The code has been specifically formatted to illustrate what we gain from this approach. <code>x_rv</code>, <code>y_rv</code> and <code>z_rv</code> have lost their direct dependency; we could easily execute these three statements in parallel. What we have done implicitly is to create two graphs: the graph between random variables which reflects the dependencies (or lack thereof) on each other's values, and the graph of the updates of the PRNG states. These graphs almost evolve in parallel.
</p>

<p>
This is similat to what I understand the <code>RandomStream</code> interface does: moving the updates of the PRNG states to the <code>update</code> graphs generated by Aesara's shared variables.
</p>

<p>
The <code>next</code> operator is however not completely satisfactory. Let us consider a more complex situation, where <code>call</code> is a function that requires a <code>RandomState</code>:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">rng</span> = at.random.RandState(0)
<span style="color: #DFAF8F;">rng_y</span> = at.random.<span style="color: #DCDCCC; font-weight: bold;">next</span>(rng)

<span style="color: #DFAF8F;">x_rv</span> = call(rng_x)
<span style="color: #DFAF8F;">y_rv</span> = call(rng_y)
<span style="color: #DFAF8F;">z_at</span> = x_rv + y_rv
</pre>
</div>

<p>
We can easily find an implementation of <code>call</code> that makes the previous code generate a random state collision:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">call</span>(rng_a):
    <span style="color: #DFAF8F;">a_rv</span> = at.random.normal(rng_a, 0, 1)
    <span style="color: #DFAF8F;">rng_b</span> = at.random.<span style="color: #DCDCCC; font-weight: bold;">next</span>(rng_a)
    <span style="color: #DFAF8F;">b_rv</span> = at.random.normal(rng_b, 0, 1)
    <span style="color: #F0DFAF; font-weight: bold;">return</span> a_rv * b_rv
</pre>
</div>

<p>
To avoid this kind of issues, we must thus require user-defined functions to return the last PRNG state along the result:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">call</span>(rng_a):
    <span style="color: #DFAF8F;">a_rv</span> = at.random.normal(rng_a, 0, 1)
    <span style="color: #DFAF8F;">rng_b</span> = at.random.<span style="color: #DCDCCC; font-weight: bold;">next</span>(rng_a)
    <span style="color: #DFAF8F;">b_rv</span> = at.random.normal(rng_b, 0, 1)
    <span style="color: #F0DFAF; font-weight: bold;">return</span> (a_rv * b_rv), at.random.<span style="color: #DCDCCC; font-weight: bold;">next</span>(rng_b)


<span style="color: #DFAF8F;">rng</span> = at.random.RandState(0)
<span style="color: #DFAF8F;">x_rv</span>, <span style="color: #DFAF8F;">rng_x</span> = call(rng)
<span style="color: #DFAF8F;">y_rv</span>, <span style="color: #DFAF8F;">rng_y</span> = call(rng_x)
<span style="color: #DFAF8F;">z_at</span> = x_rv + y_rv
</pre>
</div>

<p>
Threading PRNG state is still necessary to guarantee correctness and the two <code>call</code> functions cannot be called in parallel. The issue arises because, even though we have separated PRNG state update and random value generation, our symbolic structure is still <i>sequential</i>: each <code>RandState</code> has one and only one ancestor. We can of course circumvent this issue knowing how many times <code>next</code> is called within the function, by "jumping" the same number of times to obtain <code>rng_y</code>, but this can quickly become complex (what if <code>call</code> is imported from somewhere else?).
</p>

<p>
It would make things easier if a <code>RandState</code>\s could have several children, and if each of these child led to separate streams of random number. Let us define the following <code>split</code> operator:
</p>

<div class="org-src-container">
<pre class="src src-haskell">split :: RandState -&gt; (RandState, RandState)
</pre>
</div>

<p>
We require that we can never get the same <code>RandState</code> by calling <code>split</code> any number of times on either the left or right returned state. In other words, <code>split</code> should implicitly defines a binary tree in which all the nodes are unique. This can be easily represented by letting <code>RandState</code> holding a number in binary format. The leftmost child state is obtained by appending <code>0</code> to the parent's state and the rightmost child state by appending <code>1</code>:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">from</span> typing <span style="color: #F0DFAF; font-weight: bold;">import</span> NamedTuple


<span style="color: #F0DFAF; font-weight: bold;">class</span> <span style="color: #7CB8BB;">RandState</span>(NamedTuple):
    key: <span style="color: #DCDCCC; font-weight: bold;">int</span>
    node_id: <span style="color: #DCDCCC; font-weight: bold;">int</span> = 0b1


<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">split</span>(rng):
    <span style="color: #DFAF8F;">left</span> = RandState(rng.key, rng.node_id &lt;&lt; 2)
    <span style="color: #DFAF8F;">right</span> = RandState(rng.key, (rng.node_id &lt;&lt; 2) + 1)
    <span style="color: #F0DFAF; font-weight: bold;">return</span> left, right


<span style="color: #DFAF8F;">rng</span> = RandState(0)
<span style="color: #DFAF8F;">l</span>, <span style="color: #DFAF8F;">r</span> = split(rng)
<span style="color: #DFAF8F;">ll</span>, <span style="color: #DFAF8F;">lr</span> = split(l)

<span style="color: #F0DFAF; font-weight: bold;">print</span>(rng, l, lr)
<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">RandState(key=0, node_id=1) RandState(key=0, node_id=4) RandState(key=0, node_id=17)</span>
</pre>
</div>

<p>
If the generator called by <code>RandomVariable</code> can be made a deterministic function of this binary value, the computations are fully reproducible. We added a <code>key</code> attribute that can be specified by the user at initialization to seed the PRNG state. The tree structure is of course explicit in our graph representation, since <code>l</code> and <code>r</code> depend on <code>rng</code> via the <code>split</code> operator. Nevertheless, we can increment this internal state when building the graph in a way that allows us to compile without traversing the graph.
</p>

<p>
The <code>next</code> operator we previously defined becomes redundant within this representation. Since its interaction with the <code>split</code> operator would require careful thought we leave it aside in the following. Using the new operator our toy example becomes:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">rng</span> = at.random.RandState(0)
<span style="color: #DFAF8F;">rng_x</span>, <span style="color: #DFAF8F;">rng_y</span> = at.random.split(rng)

<span style="color: #DFAF8F;">x_rv</span> = at.random.normal(rng_x, 0, 1)
<span style="color: #DFAF8F;">y_rv</span> = at.random.normal(rng_y, 0, 1)
<span style="color: #DFAF8F;">z_at</span> = x_rv + y_rv
</pre>
</div>

<p>
Note that the "main" sub-graph that contains random variables, and the PRNG sub-graph are still minimally connected.
</p>

<p>
Finally, it is also natural to implement the <code>splitn</code> operator represented by:
</p>

<div class="org-src-container">
<pre class="src src-haskell">splitn :: RandState -&gt; Int -&gt; (RandState, ..., RandState)
</pre>
</div>

<p>
So we can write the following code:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">at.random.split</span> = at.random.Split()

<span style="color: #DFAF8F;">rng</span> = at.random.default_rng()
<span style="color: #DFAF8F;">rng_v</span>, <span style="color: #DFAF8F;">rng_w</span>, <span style="color: #DFAF8F;">rng_x</span>, <span style="color: #DFAF8F;">rng_y</span> = at.random.splitn(rng, 4)

<span style="color: #DFAF8F;">v_rv</span> = at.random.normal(rng_y, 0, 1)
<span style="color: #DFAF8F;">w_rv</span> = at.random.normal(rng_x, 0, 1)
<span style="color: #DFAF8F;">x_rv</span> = at.random.normal(rng_x, 0, 1)
<span style="color: #DFAF8F;">y_rv</span> = at.random.normal(rng_y, 0, 1)
<span style="color: #DFAF8F;">z_at</span> = v_rv + w_rv + x_rv + z_rv
</pre>
</div>
</div>
<div id="outline-container-org1ea837f" class="outline-4">
<h4 id="org1ea837f">Implementation</h4>
<div class="outline-text-4" id="text-org1ea837f">
<p>
When it comes to practical implementations, this representation is only convenient for counter-based PRNGs like <code>Philox</code> implemented in NumPy: we generate a pair of <code>(key, counter)</code> from our <code>RandState</code>\s and pass these as an input to the generator.
</p>
</div>


<ul class="org-ul">
<li><a id="org3067dc5"></a><code>RandState</code> and <code>split</code> implementation<br />
<div class="outline-text-5" id="text-org3067dc5">
<p>
The mock implementation of <code>RandState</code> and <code>split</code> above is naive in the sense that the counter space \(\mathcal{S}\) of real PRNGs does not usually extend indefinitely. In practice we will need to compress the state using a hashing function that also increments the <code>key</code>. To be immediately compatible with NumPy in the <code>perform</code> function we can use Philox's hash function to update the state as we build the graph. Since the hash is deterministic we can still walk the <code>RandState</code> tree in our representation and cheaply recompute the states should we need to.
</p>

<p>
<i>Op and Variable implementations to come.</i>
</p>
</div>
</li>

<li><a id="org7aa2f09"></a><code>=RandomVariable</code><br />
<div class="outline-text-5" id="text-org7aa2f09">
<p>
The modifications to <code>RandomVariable</code> Ops are minimal:
</p>

<ul class="org-ul">
<li><code>__call__</code> now takes a <code>RandState</code> as a positional argument;</li>
<li><code>make_node</code> only returns <code>out_var</code>. The <code>default_output</code> attribute is not needed anymore.</li>
</ul>
</div>
</li>

<li><a id="org44d6767"></a><code>RandomStream</code><br />
<div class="outline-text-5" id="text-org44d6767">
<p>
We can keep the <code>RandomStream</code> API, use a shared variable to hold the <code>RandState</code> and handle the splitting internally. The RNG sub-graphs are now found in the updates' graph.
</p>

<p>
<i>In a second time we may consider instantiating <code>RandState</code> as shared variables by default to decouple both the random variable and the PRNG state graphs. I am not sure of the tradeoffs here, but it may alleviate concerns related to graph rewrites.</i>
</p>
</div>
</li>
</ul>
</div>

<div id="outline-container-orgb0e0df1" class="outline-4">
<h4 id="orgb0e0df1">Compilation</h4>
<div class="outline-text-4" id="text-orgb0e0df1">
<p>
It is essential that our representation of PRNG states and <code>RandomVariable</code>\s in the graph can be easily transpiled to the existing targets (C, Numba, JAX) and future targets. In the following I outline the transpilation process for the current targets.
</p>
</div>

<ul class="org-ul">
<li><a id="orga8464c6"></a>Numba<br />
<div class="outline-text-5" id="text-orga8464c6">
<p>
After <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aesara/pull/1245">#1245</a> Aesara will support NumPy's Generator API. Furthermore NumPy has support for <a target='_blank' rel='noopener noreferrer' class='external' href="https://numpy.org/doc/stable/reference/random/bit_generators/philox.html">Philox as a BitGenerator</a>, a <a target='_blank' rel='noopener noreferrer' class='external' href="http://www.thesalmons.org/john/random123/papers/random123sc11.pdf">counter-based PRNG</a> which can easily accomodate <a target='_blank' rel='noopener noreferrer' class='external' href="https://publications.lib.chalmers.se/records/fulltext/183348/local_183348.pdf">splittable PRNG representations</a>. Assuming we can map each path in the PRNG graph to a <code>(key, counter)</code> tuple, the transpilation of <code>RandomStream</code>\s using the Philox <code>BitGenerator</code> should be straighforward. For the explicit splitting interface, we can directly translate the <code>RandomVariable</code>\s to NumPy <code>Generator</code>\s and seed these generators at compile time. So that:
</p>

<div class="org-src-container">
<pre class="src src-python">at.random.normal(rng, 0, 1)
</pre>
</div>

<p>
Becomes:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">gen</span> = np.random.Generator(np.random.Philox(counter=rng.counter, key=rng.key))
gen.normal(0, 1)
</pre>
</div>
</div>
</li>

<li><a id="orgf873966"></a>JAX<br />
<div class="outline-text-5" id="text-orgf873966">
<p>
Transpilation to JAX would be straightforward, as JAX <a target='_blank' rel='noopener noreferrer' class='external' href="https://jax.readthedocs.io/en/latest/jep/263-prng.html">uses a splittable PRNG representation</a>. We will simply need to perform the following substitutions:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">rng</span> = at.random.RandomState()
<span style="color: #DFAF8F;">rng_key</span> = jax.random.PRNGKey()

at.random.split(rng)
jax.random.split(rng_key)

at.random.splitn(rng, 10)
jax.random.split(rng_key, 10)
</pre>
</div>
</div>
</li>
</ul>
</div>
</div>

<div id="outline-container-org9bec64c" class="outline-3">
<h3 id="org9bec64c">Back to the motivating issues</h3>
<div class="outline-text-3" id="text-org9bec64c">
<p>
The problems linked to the existence of the <code>default_output</code> attribute disappear since <code>RandomVariable</code>\s do not return PRNG states anymore. The one-to-many difficulty we are facing with the relations between etuplized graphs also disappears with a <code>split</code> operator. Using the example from the beginning we can for instance write:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">from</span> etuples <span style="color: #F0DFAF; font-weight: bold;">import</span> etuple
<span style="color: #F0DFAF; font-weight: bold;">from</span> kanren <span style="color: #F0DFAF; font-weight: bold;">import</span> var

<span style="color: #DFAF8F;">mu_x</span>, <span style="color: #DFAF8F;">mu_y</span>, <span style="color: #DFAF8F;">sigma2_x</span>, <span style="color: #DFAF8F;">sigma2_y</span> = var(), var(), var(), var()

<span style="color: #DFAF8F;">rng</span>, <span style="color: #DFAF8F;">size</span>, <span style="color: #DFAF8F;">dtype</span> = var(), var(), var()
<span style="color: #DFAF8F;">X_et</span> = etuple(
    etuplize(at.random.normal),
    rng,
    size,
    dtype,
    etuple(
        etuplize(at.add),
        mu_x,
        mu_y
    ),
    etuple(
        etuplize(at.add),
        sigma2_x,
        sigma2_y,
    )
)

<span style="color: #DFAF8F;">rng_x</span>, <span style="color: #DFAF8F;">size_x</span>, <span style="color: #DFAF8F;">dtype_x</span> = var(), var(), var()
<span style="color: #DFAF8F;">rng_y</span>, <span style="color: #DFAF8F;">size_y</span>, <span style="color: #DFAF8F;">dtype_y</span> = var(), var(), var()
<span style="color: #DFAF8F;">Y_et</span> = etuple(
    etuplize(at.add),
    etuple(
        etuplize(at.random.normal),
        etuple(
            nth,
            0,
            etuple(
                split,
                rng,
            )
        ),
        size_x,
        dtype_x,
        mu_x,
        sigma2_x
    ),
    etuple(
        etuplize(at.random.normal),
        etuple(
            nth,
            1,
            etuple(
                split,
                rng,
            )
        ),
        size_y,
        dtype_y,
        mu_y,
        sigma2_y
    )
)
</pre>
</div>

<p>
Which is guaranteed to be collision-free by construction of the <code>split</code> operator, as long as the PRNG state used by the original normal distribution isn't passed to a <code>split</code> operator somewhere else in the original graph (<b>todo:</b> specify API requirements to guarantee uniqueness of the random numbers).
</p>
</div>
</div>

<div id="outline-container-org71f357b" class="outline-3">
<h3 id="org71f357b">Playground</h3>
<div class="outline-text-3" id="text-org71f357b">
<p>
We would like to be able to control randomness from outside of Aesara. From JAX it is rather clear how that would work:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara

<span style="color: #DFAF8F;">rng</span> = at.random.RNGState()
<span style="color: #DFAF8F;">result</span> = at.random.normal(rng, 0, 1)

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">JAX compilation</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> jax

<span style="color: #DFAF8F;">fn</span> = aesara.function([rng], result, mode=<span style="color: #CC9393;">"JAX"</span>)
<span style="color: #DFAF8F;">rng_key</span> = jax.random.PRNGKey(0)
fn(rng_key)
</pre>
</div>

<p>
But for NumPy/Numba it is not as clear what we should be using.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Numba compilation</span>
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">fn</span> = aesara.function([rng], result, mode=<span style="color: #CC9393;">"JAX"</span>)
<span style="color: #DFAF8F;">rng_key</span> = np.random.default_rng(0)
fn(rng_key)

</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org965cfa9" class="outline-2">
<h2 id="org965cfa9">RandomVariable Ops</h2>
<div class="outline-text-2" id="text-org965cfa9">
<p>
We have a <code>default_rng</code> function, but the result does not behave as a generator in <code>numpy</code>.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">from</span> aesara.tensor.random <span style="color: #F0DFAF; font-weight: bold;">import</span> default_rng
<span style="color: #DFAF8F;">rng</span> = default_rng(32)
rng.<span style="color: #DCDCCC; font-weight: bold;">type</span>
</pre>
</div>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">from</span> aesara.tensor.random.basic <span style="color: #F0DFAF; font-weight: bold;">import</span> NormalRV

<span style="color: #DFAF8F;">norm</span> = NormalRV()
<span style="color: #DFAF8F;">norm_rv</span> = norm(0, 1, size=(2,), rng=rng)

norm_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
</pre>
</div>


<p>
<code>Aesara</code> also defines aliases for the <code>RandomVariable</code> Ops:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">from</span> aesara.tensor.random <span style="color: #F0DFAF; font-weight: bold;">import</span> normal

<span style="color: #DFAF8F;">normal_rv</span> = normal(0, 1, size=(2,), rng=rng)
normal_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
</pre>
</div>

<p>
Let's look at the graphs that are produced:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara
<span style="color: #F0DFAF; font-weight: bold;">from</span> aesara.tensor.random <span style="color: #F0DFAF; font-weight: bold;">import</span> default_rng, normal

<span style="color: #DFAF8F;">rng</span> = default_rng(0)
<span style="color: #DFAF8F;">a_rv</span> = normal(0, 1, rng=rng)
<span style="color: #DFAF8F;">b_rv</span> = normal(0, 1, rng=rng)
<span style="color: #DFAF8F;">c_tt</span> = a_rv + b_rv

<span style="color: #DFAF8F;">d_rv</span> = normal(0, 1, rng=rng)

aesara.dprint(c_tt * d_rv)
</pre>
</div>


<p>
How does <code>RandomGeneratorType</code> work? It looks like it has internal state.
</p>
</div>
</div>

<div id="outline-container-org6636d0a" class="outline-2">
<h2 id="org6636d0a">Define custom random variables</h2>
<div class="outline-text-2" id="text-org6636d0a">
<p>
It is fairly simple as <code>srng.gen(RV, *args)</code> will call <code>RV()(random_state, *args)</code>.
</p>

<div class="org-src-container">
<pre class="src src-python">srng.gen(zero_truncated_betabinom, eta_at, kappa_rv, n_at),
</pre>
</div>

<p>
where the <code>RandomVariable</code> is implemented as:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">class</span> <span style="color: #7CB8BB;">ZeroTruncatedBetaBinomial</span>(RandomVariable):
    r<span style="color: #9FC59F;">"""A zero-truncated beta-binomial distribution.</span>

<span style="color: #9FC59F;">    This distribution is implemented in the :math:`\kappa`</span>
<span style="color: #9FC59F;">    and :math:`\eta` parameterization, which is related to</span>
<span style="color: #9FC59F;">    the standard :math:`\alpha` and :math:`\beta` parameterization</span>
<span style="color: #9FC59F;">    of the beta-binomial through the following:</span>

<span style="color: #9FC59F;">    .. math::</span>
<span style="color: #9FC59F;">        \alpha = \eta / \kappa \\</span>
<span style="color: #9FC59F;">        \beta = (1 - \eta) / \kappa</span>

<span style="color: #9FC59F;">    Truncation aside, for a :math:`Y \sim \operatorname{BetaBinom}\left(N, \eta, \kappa\right)`,  # noqa: E501</span>

<span style="color: #9FC59F;">    .. math::</span>
<span style="color: #9FC59F;">        \operatorname{E}\left[ Y \right] = N \eta \\</span>
<span style="color: #9FC59F;">        \operatorname{Var}\left[ Y \right] = N \eta (1 - \eta) (N \kappa + 1) / (\kappa + 1)</span>


<span style="color: #9FC59F;">    Under this parameterization, :math:`\kappa` in the standard beta-binomial</span>
<span style="color: #9FC59F;">    serves as an over-dispersion term with the following properties:</span>

<span style="color: #9FC59F;">    .. math::</span>
<span style="color: #9FC59F;">        \lim_{\kappa \to 0} \operatorname{Var}\left[ Y \right] = N \eta (1 - \eta) \\</span>
<span style="color: #9FC59F;">        \lim_{\kappa \to \infty} \operatorname{Var}\left[ Y \right] = N^2 \eta (1 - \eta)</span>

<span style="color: #9FC59F;">    In other words, :math:`\kappa` modulates between the standard binomial</span>
<span style="color: #9FC59F;">    variance and :math:`N`-times that variance.</span>

<span style="color: #9FC59F;">    The un-truncated probability mass function (PMF) is as follows:</span>

<span style="color: #9FC59F;">    .. math::</span>
<span style="color: #9FC59F;">        \frac{\operatorname{B}\left(\frac{\eta}{\kappa} + y, n - y + \frac{1 - \eta}{\kappa}\right) {\binom{n}{y}}}{\operatorname{B}\left(\frac{\eta}{\kappa}, \frac{1 - \eta}{\kappa}\right)}  # noqa: E501</span>

<span style="color: #9FC59F;">    and the zero-truncated PMF is as follows:</span>

<span style="color: #9FC59F;">    .. math::</span>
<span style="color: #9FC59F;">        \frac{\operatorname{B}\left(\frac{\eta}{\kappa} + y, - \frac{\eta}{\kappa} + n - y + \frac{1}{\kappa}\right) {\binom{n}{y}}}{\operatorname{B}\left(\frac{\eta}{\kappa}, - \frac{\eta}{\kappa} + \frac{1}{\kappa}\right) - \operatorname{B}\left(\frac{\eta}{\kappa}, - \frac{\eta}{\kappa} + n + \frac{1}{\kappa}\right)}  # noqa: E501</span>

<span style="color: #9FC59F;">    """</span>
    <span style="color: #DFAF8F;">name</span> = <span style="color: #CC9393;">"zero_truncated_betabinom"</span>
    <span style="color: #DFAF8F;">ndim_supp</span> = 0
    <span style="color: #DFAF8F;">ndims_params</span> = [0, 0, 0]
    <span style="color: #DFAF8F;">dtype</span> = <span style="color: #CC9393;">"int64"</span>
    <span style="color: #DFAF8F;">_print_name</span> = (<span style="color: #CC9393;">"ZeroTruncBetaBinom"</span>, <span style="color: #CC9393;">"\\operatorname{BetaBinom}_{&gt;0}"</span>)

    <span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">__init__</span>(<span style="color: #F0DFAF; font-weight: bold;">self</span>, rejection_threshold=200, **kwargs):
        <span style="color: #9FC59F;">"""</span>
<span style="color: #9FC59F;">        Parameters</span>
<span style="color: #9FC59F;">        ----------</span>
<span style="color: #9FC59F;">        rejection_threshold</span>
<span style="color: #9FC59F;">            The number of rejection iterations to perform before raising an</span>
<span style="color: #9FC59F;">            exception.</span>
<span style="color: #9FC59F;">        """</span>
        <span style="color: #F0DFAF; font-weight: bold;">self</span>.rejection_threshold = rejection_threshold
        <span style="color: #DCDCCC; font-weight: bold;">super</span>().__init__(**kwargs)

    <span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">__call__</span>(<span style="color: #F0DFAF; font-weight: bold;">self</span>, eta, kappa, n, size=<span style="color: #BFEBBF;">None</span>, **kwargs):
        <span style="color: #9FC59F;">"""</span>
<span style="color: #9FC59F;">        Parameters</span>
<span style="color: #9FC59F;">        ----------</span>
<span style="color: #9FC59F;">        eta</span>
<span style="color: #9FC59F;">        kappa</span>
<span style="color: #9FC59F;">        n</span>
<span style="color: #9FC59F;">        """</span>

        <span style="color: #F0DFAF; font-weight: bold;">self</span>.eta = at.as_tensor_variable(eta, dtype=aesara.config.floatX)
        <span style="color: #F0DFAF; font-weight: bold;">self</span>.kappa = at.as_tensor_variable(kappa, dtype=aesara.config.floatX)
        <span style="color: #F0DFAF; font-weight: bold;">self</span>.n = at.as_tensor_variable(n, dtype=np.int64)

        <span style="color: #F0DFAF; font-weight: bold;">return</span> <span style="color: #DCDCCC; font-weight: bold;">super</span>().__call__(eta, kappa, n, size=size, **kwargs)

    <span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">rng_fn</span>(<span style="color: #F0DFAF; font-weight: bold;">self</span>, rng, eta, kappa, n, size):
        <span style="color: #9FC59F;">"""A naive hybrid rejection + inverse sampler."""</span>

        <span style="color: #DFAF8F;">n</span> = np.asarray(n, dtype=np.int64)
        <span style="color: #DFAF8F;">eta</span> = np.asarray(eta, dtype=np.float64)
        <span style="color: #DFAF8F;">kappa</span> = np.asarray(kappa, dtype=np.float64)

        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">Values below this will produce errors (plus, it means this is really</span>
        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">a binomial)</span>
        <span style="color: #DFAF8F;">alpha</span> = np.clip(eta / kappa, near_zero, 1e100)
        <span style="color: #DFAF8F;">beta</span> = np.clip((1 - eta) / kappa, near_zero, 1e100)

        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">def zt_bb_inv(n, alpha, beta, size=None):</span>
        <span style="color: #5F7F5F;">#     </span><span style="color: #7F9F7F;">"""A zero-truncated beta-binomial inverse sampler."""</span>
        <span style="color: #5F7F5F;">#     </span><span style="color: #7F9F7F;"># bb_dist = scipy.stats.betabinom(n, alpha, beta)</span>
        <span style="color: #5F7F5F;">#     </span><span style="color: #7F9F7F;">beta_smpls = np.clip(</span>
        <span style="color: #5F7F5F;">#         </span><span style="color: #7F9F7F;">scipy.stats.beta(alpha, beta).rvs(size=size), 1e-10, np.inf</span>
        <span style="color: #5F7F5F;">#     </span><span style="color: #7F9F7F;">)</span>
        <span style="color: #5F7F5F;">#     </span><span style="color: #7F9F7F;">binom_dist = scipy.stats.binom(n, beta_smpls)</span>
        <span style="color: #5F7F5F;">#     </span><span style="color: #7F9F7F;">u = np.random.uniform(size=size)</span>
        <span style="color: #5F7F5F;">#     </span><span style="color: #7F9F7F;">F_0 = binom_dist.cdf(0)</span>
        <span style="color: #5F7F5F;">#     </span><span style="color: #7F9F7F;">samples = binom_dist.ppf(F_0 + u * (1 - F_0))</span>
        <span style="color: #5F7F5F;">#     </span><span style="color: #7F9F7F;">return samples</span>

        <span style="color: #DFAF8F;">samples</span> = scipy.stats.betabinom(n, alpha, beta).rvs(size=size, random_state=rng)
        <span style="color: #DFAF8F;">alpha</span> = np.broadcast_to(alpha, samples.shape)
        <span style="color: #DFAF8F;">beta</span> = np.broadcast_to(beta, samples.shape)
        <span style="color: #DFAF8F;">n</span> = np.broadcast_to(n, samples.shape)
        <span style="color: #DFAF8F;">rejects</span> = samples &lt;= 0

        <span style="color: #DFAF8F;">thresh_count</span> = 0
        <span style="color: #F0DFAF; font-weight: bold;">while</span> rejects.<span style="color: #DCDCCC; font-weight: bold;">any</span>():
            <span style="color: #DFAF8F;">_n</span> = n[rejects] <span style="color: #F0DFAF; font-weight: bold;">if</span> np.size(n) &gt; 1 <span style="color: #F0DFAF; font-weight: bold;">else</span> n
            <span style="color: #DFAF8F;">_alpha</span> = alpha[rejects] <span style="color: #F0DFAF; font-weight: bold;">if</span> np.size(alpha) &gt; 1 <span style="color: #F0DFAF; font-weight: bold;">else</span> alpha
            <span style="color: #DFAF8F;">_beta</span> = beta[rejects] <span style="color: #F0DFAF; font-weight: bold;">if</span> np.size(beta) &gt; 1 <span style="color: #F0DFAF; font-weight: bold;">else</span> beta
            <span style="color: #DFAF8F;">_size</span> = rejects.<span style="color: #DCDCCC; font-weight: bold;">sum</span>()

            <span style="color: #DFAF8F;">beta_smpls</span> = np.clip(
                scipy.stats.beta(_alpha, _beta).rvs(size=_size, random_state=rng),
                near_zero,
                near_one,
            )
            <span style="color: #DFAF8F;">samples</span>[rejects] = scipy.stats.binom(_n, beta_smpls).rvs(
                size=_size, random_state=rng
            )
            <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">samples[rejects] = scipy.stats.betabinom(_n, _alpha, _beta).rvs(size=_size)  # noqa: E501</span>

            <span style="color: #DFAF8F;">new_rejects</span> = samples &lt;= 0
            <span style="color: #F0DFAF; font-weight: bold;">if</span> new_rejects.<span style="color: #DCDCCC; font-weight: bold;">sum</span>() == rejects.<span style="color: #DCDCCC; font-weight: bold;">sum</span>():
                <span style="color: #F0DFAF; font-weight: bold;">if</span> thresh_count &gt; <span style="color: #F0DFAF; font-weight: bold;">self</span>.rejection_threshold:
                    <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;"># Attempt rejection sampling until the rejection results</span>
                    <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;"># get stuck, then use the inverse-sampler</span>
                    <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">samples[rejects] = zt_bb_inv(_n, _alpha, _beta, size=_size)</span>
                    <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">break</span>
                    <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">raise ValueError("The sampling rejection threshold was met")</span>
                    warnings.warn(
                        <span style="color: #CC9393;">"The sampling rejection threshold was met "</span>
                        <span style="color: #CC9393;">"and mean values were used as sample values"</span>
                    )
                    <span style="color: #DFAF8F;">sp_ref_dist</span> = scipy.stats.betabinom(_n, _alpha, _beta)
                    <span style="color: #DFAF8F;">trunc_mean</span> = sp_ref_dist.mean() / (1 - sp_ref_dist.cdf(0))
                    <span style="color: #F0DFAF; font-weight: bold;">assert</span> np.<span style="color: #DCDCCC; font-weight: bold;">all</span>(trunc_mean &gt;= 1)
                    <span style="color: #DFAF8F;">samples</span>[rejects] = trunc_mean
                    <span style="color: #F0DFAF; font-weight: bold;">break</span>
                <span style="color: #F0DFAF; font-weight: bold;">else</span>:
                    <span style="color: #DFAF8F;">thresh_count</span> += 1
            <span style="color: #F0DFAF; font-weight: bold;">else</span>:
                <span style="color: #DFAF8F;">thresh_count</span> = 0

            <span style="color: #DFAF8F;">rejects</span> = new_rejects

        <span style="color: #F0DFAF; font-weight: bold;">return</span> samples


<span style="color: #DFAF8F;">zero_truncated_betabinom</span> = ZeroTruncatedBetaBinomial()


<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">_logp</span>(value, eta, kappa, n):
    <span style="color: #F0DFAF; font-weight: bold;">return</span> (
        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">binomln(n, value)</span>
        -at.log(n + 1)
        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">- betaln(n - value + 1, value + 1)</span>
        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">+ betaln(value + alpha, n - value + beta)</span>
        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">- betaln(alpha, beta)</span>
        - at.gammaln(n - value + 1)
        - at.gammaln(value + 1)
        + at.gammaln(n + 2)
        + at.gammaln(value + eta / kappa)
        + at.gammaln(n - value + (1 - eta) / kappa)
        - at.gammaln(1 / kappa + n)
        - at.gammaln(eta / kappa)
        - at.gammaln((1 - eta) / kappa)
        + at.gammaln(1 / kappa)
    )


<span style="color: #7CB8BB;">@_logprob.register</span>(ZeroTruncatedBetaBinomial)
<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">zero_truncated_betabinom_logprob</span>(op, values, *inputs, **kwargs):
    (values,) = values
    (eta, kappa, n) = inputs[3:]

    <span style="color: #DFAF8F;">l0</span> = (
        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">gammaln(alpha + beta)</span>
        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">+ gammaln(n + beta)</span>
        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">- gammaln(beta)</span>
        <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">- gammaln(alpha + beta + n)</span>
        at.gammaln(1 / kappa)
        + at.gammaln(n + (1 - eta) / kappa)
        - at.gammaln((1 - eta) / kappa)
        - at.gammaln(1 / kappa + n)
    )

    <span style="color: #DFAF8F;">log1mP0</span> = at.log1mexp(l0)
    <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">log1mP0 = 0</span>

    <span style="color: #DFAF8F;">res</span> = CheckParameterValue(<span style="color: #CC9393;">"values &lt;= n, eta &gt; 0, kappa &gt; 0"</span>)(
        at.switch(values &gt; 0, _logp(values, eta, kappa, n) - log1mP0, -np.inf),
        at.<span style="color: #DCDCCC; font-weight: bold;">all</span>(values &lt;= n),
        at.<span style="color: #DCDCCC; font-weight: bold;">all</span>(eta &gt; 0),
        at.<span style="color: #DCDCCC; font-weight: bold;">all</span>(kappa &gt; 0),
    )
    <span style="color: #F0DFAF; font-weight: bold;">return</span> res
</pre>
</div>

<p>
Note that you can also define this random variables' logprob dispatching <code>_logprob</code> for the <code>ZeroTruncBetaBinom</code>.
</p>
</div>
</div>

<div id="outline-container-orgb559edd" class="outline-2">
<h2 id="orgb559edd">Sampling vs Logprobability <code>aeppl</code></h2>
<div class="outline-text-2" id="text-orgb559edd">
<ul class="org-ul">
<li>How define the logprob of a custom distribution?</li>
</ul>
</div>
</div>

<div id="outline-container-org86c7438" class="outline-2">
<h2 id="org86c7438">Shapes</h2>
<div class="outline-text-2" id="text-org86c7438">
<p>
Shapes are always a mess when it comes to random variables. In <code>aesara</code> we note two distinct shapes:
</p>
<ul class="org-ul">
<li><code>ndim_supp</code> the number of dimensions of the RV's support.</li>
<li><code>ndim_params</code></li>
<li><code>size</code> which is the sample size</li>
</ul>

<p>
Remember that shapes in Aesara can be determined at runtime! So if we assume that:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">batch_shape</span> = size
np.ndim(sample_shape) = ndim_supp
<span style="color: #DFAF8F;">shape</span> = sample_shape + batch_shape
</pre>
</div>

<p>
And we should have a look at broadcasting rules because they are not all very obvious.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">from</span> aesara.tensor.random <span style="color: #F0DFAF; font-weight: bold;">import</span> RandomStream

<span style="color: #DFAF8F;">srng</span> = RandomStream(0)
<span style="color: #DFAF8F;">a_rv</span> = srng.normal(0, 1, size=(2,3))
<span style="color: #F0DFAF; font-weight: bold;">print</span>(a_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>())
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">mu</span> = at.as_tensor([1., 2., 3.])
<span style="color: #DFAF8F;">a_rv</span> = srng.normal(mu, 1, size=(2,3))
<span style="color: #F0DFAF; font-weight: bold;">print</span>(a_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>())
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">mu</span> = at.as_tensor([1., 2.])
<span style="color: #DFAF8F;">a_rv</span> = srng.normal(mu, 1, size=(2,3))
<span style="color: #F0DFAF; font-weight: bold;">print</span>(a_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>())
</pre>
</div>

<p>
More complex is the case where the random variable is non-scalar, as multivariate normal. Here you can see that the "event shape" is equal to 2. The resulting shape, if we assume <code>event_shape</code> and <code>batch_shape</code> are tuples is given by:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #DFAF8F;">shape</span> = event_shape + batch_shape
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">mu</span> = np.r_[1, 2]
<span style="color: #DFAF8F;">sigma</span> = np.array([[.5, .5], [.4, .6]])
<span style="color: #DFAF8F;">a_rv</span> = srng.multivariate_normal(mu, sigma, size=(2, 5))
<span style="color: #F0DFAF; font-weight: bold;">print</span>(a_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>().shape)
</pre>
</div>

<p>
See <a target='_blank' rel='noopener noreferrer' class='external' href="https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/">Eric Ma's blog post on the topic</a>.
</p>
</div>
</div>

<div id="outline-container-org477702d" class="outline-2">
<h2 id="org477702d">Problems with <code>RandomStream</code></h2>
<div class="outline-text-2" id="text-org477702d">
<p>
<a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aesara/pull/1211#discussion_r985057882">https://github.com/aesara-devs/aesara/pull/1211#discussion_r985057882</a>
</p>
</div>
</div>

<div id="outline-container-orgeccb575" class="outline-2">
<h2 id="orgeccb575">Proposal</h2>
<div class="outline-text-2" id="text-orgeccb575">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">rng</span> = at.random.RandomState()

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">RandomVariables divide the rng</span>
<span style="color: #DFAF8F;">a_rv</span>, <span style="color: #DFAF8F;">rng</span> = at.random.normal(rng, 0, 1)
<span style="color: #DFAF8F;">b_rv</span>, <span style="color: #DFAF8F;">_</span> = at.random.normal(rng, 0, 1)

<span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">We have to update the rng manually</span>
<span style="color: #DFAF8F;">a_rv</span> = at.random.normal(rng, 0, 1)
<span style="color: #DFAF8F;">rng</span> = at.random.update(rng)
<span style="color: #DFAF8F;">b_rv</span> = at.random.normal(rng, 0, 1)

<span style="color: #DFAF8F;">rng_a</span>, <span style="color: #DFAF8F;">rng_b</span> = at.random.split(rng)
<span style="color: #DFAF8F;">a_rv</span> = at.random.normal(rng_a, 0, 1)
<span style="color: #DFAF8F;">b_rv</span> = at.random.normal(rng_b, 0, 1)

<span style="color: #DFAF8F;">rngs</span> = at.random.split(rng, 10)
<span style="color: #DFAF8F;">rvs</span> = []
<span style="color: #F0DFAF; font-weight: bold;">for</span> rng <span style="color: #F0DFAF; font-weight: bold;">in</span> rngs:
    rvs.append(at.random.normal(rng, 0, 1))
</pre>
</div>

<p>
How does that solve the previous issues?
</p>

<ol class="org-ol">
<li>Monkey patching to specialize the RV <code>Op</code>\s</li>
<li>RVs in S-expressions and rewrites</li>
</ol>

<p>
What does that complicate?
</p>

<div class="org-src-container">
<pre class="src src-python">
<span style="color: #F0DFAF; font-weight: bold;">def</span> <span style="color: #93E0E3;">standard_normal</span>():

</pre>
</div>
</div>
</div>

<div id="outline-container-orgb47bce5" class="outline-2">
<h2 id="orgb47bce5">Links to this note</h2>
<div class="outline-text-2" id="text-orgb47bce5">
<ul class="org-ul">
<li><a href="./20220729163627-aesara.html">Aesara</a></li>
<li><a href="./inbox.html">Writing inbox</a></li>
</ul>
</div>
</div>
</div>
</body>
</html>