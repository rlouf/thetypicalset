<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-08-24 Wed 22:24 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Stochastic gradient Langevin Dynamics (SgLD)</title>
<meta name="author" content="RÃ©mi Louf" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="style.css" /><script data-goatcounter="https://thetypicalset.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Stochastic gradient Langevin Dynamics (SgLD)</h1>

<div id="outline-container-org28d9f5e" class="outline-2">
<h2 id="org28d9f5e">Principle and motivation</h2>
<div class="outline-text-2" id="text-org28d9f5e">
<p>
We use the same solver for the overdamped Langevin dynamics as for the <a href="20220329092624-metropolis_adjusted_langevin_algorithm.html#ID-2b7665c9-e950-4432-b260-9e30b593b375">Metropolis-Adjusted Langevin Algorithm</a>, but we work with an <i>estimator</i> \(\hat{\nabla} \log \pi\) for the gradient of the log-probability density function instead of the gradient itself. There are two reasons why one would want to do that:
</p>

<ul class="org-ul">
<li>When the amount of data is huge the full gradient can be very expensive to compute;</li>
<li>When there is a risk to be stuck in a region of the parameter space that is not representative of the typical set; the algorithm has annealing properties.</li>
</ul>

<p>
The exposition follows [Welling &amp; Teh]. At time \(t\) a subset \(X_t = \left\{x_{1t}, \dots, x_{nt}\right\}\) of \(n\) data items is sampled, a step size \(\epsilon_t\) is chosen. The gradient is approximated as:
</p>

<div class="org-src-container">
<pre class="src src-latex"><span style="font-weight: bold;">\begin</span>{<span style="font-weight: bold;">equation*</span>}
  <span style="font-weight: bold;">\hat</span>{<span style="font-weight: bold;">\nabla</span>} <span style="font-weight: bold;">\log</span> <span style="font-weight: bold;">\pi</span>(<span style="font-weight: bold;">\theta</span>_{t}) = <span style="font-weight: bold;">\nabla</span> <span style="font-weight: bold;">\log</span> p(<span style="font-weight: bold;">\theta</span>_{t}) + <span style="font-weight: bold;">\frac</span>{N}{n} <span style="font-weight: bold;">\sum</span>_{i} <span style="font-weight: bold;">\nabla</span> <span style="font-weight: bold;">\log</span> p(x_{it}|<span style="font-weight: bold;">\theta</span>_{t})
<span style="font-weight: bold;">\end</span>{<span style="font-weight: bold;">equation*</span>}
</pre>
</div>
<p>
So the proposed update using the Langevin dynamics is:
</p>

<div class="org-src-container">
<pre class="src src-latex"><span style="font-weight: bold;">\begin</span>{<span style="font-weight: bold;">align*</span>}
  <span style="font-weight: bold;">\theta</span>_{t+1} &amp;= <span style="font-weight: bold;">\theta</span>_{t} + <span style="font-weight: bold;">\frac</span>{<span style="font-weight: bold;">\epsilon</span>_{t}}{2}<span style="font-weight: bold;">\;\left</span>(<span style="font-weight: bold;">\nabla</span> <span style="font-weight: bold;">\log</span> p(<span style="font-weight: bold;">\theta</span>_{t}) + <span style="font-weight: bold;">\frac</span>{N}{n} <span style="font-weight: bold;">\sum</span>_{i} <span style="font-weight: bold;">\nabla</span> <span style="font-weight: bold;">\log</span> p(x_{it}|<span style="font-weight: bold;">\theta</span>_{t})<span style="font-weight: bold;">\right</span>) + <span style="font-weight: bold;">\xi</span>_{t}<span style="font-weight: bold;">\\</span>
  <span style="font-weight: bold;">\xi</span>_t &amp;<span style="font-weight: bold;">\sim</span> <span style="font-weight: bold;">\operatorname</span>{Normal}<span style="font-weight: bold;">\left</span>(0, <span style="font-weight: bold;">\epsilon</span>_t<span style="font-weight: bold;">\right</span>)
<span style="font-weight: bold;">\end</span>{<span style="font-weight: bold;">align*</span>}
</pre>
</div>


<p>
<i>We do not use RMH acceptance/rejection step</i> (which would require evaluation over the whole dataset).
</p>
</div>
</div>

<div id="outline-container-orgbfa1014" class="outline-2">
<h2 id="orgbfa1014">Convergence</h2>
</div>

<div id="outline-container-orgf783143" class="outline-2">
<h2 id="orgf783143">References</h2>
<div class="outline-text-2" id="text-orgf783143">
<ul class="org-ul">
<li>Welling &amp; Teh (2011) <a target='_blank' rel='noopener noreferrer' class='external' href="https://www.stats.ox.ac.uk/~teh/research/compstats/WelTeh2011a.pdf">Bayesian Learning via Stochastic Gradient Langevin Dynamics</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgeabe78d" class="outline-2">
<h2 id="orgeabe78d">Links to this note</h2>
</div>
</div>
</body>
</html>
