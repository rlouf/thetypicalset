<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-12-28 Thu 21:50 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Gaussian process</title>
<meta name="author" content="RÃ©mi Louf" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="style.css" /><script data-goatcounter="https://thetypicalset.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Gaussian process</h1>
<dl class="org-dl">
<dt>tags</dt><dd><a href="20220105154404-probability_distribution.html#ID-accc4a58-2f96-42da-a43d-c8140996d0d3">Probability distribution</a></dd>
</dl>

<p>
We have the follow impractical definition:
</p>

<blockquote>
<p>
A Gaussian process is a collection of random variables, any finite number of which have consistent Gaussian distributions.
</p>
</blockquote>

<p>
It is completely defined by its mean function \(m(x)\) and covariance function \(\Sigma(x, x')\). We write:
</p>

\begin{equation}
  f(x) \sim \mathcal{G}\left(m(x), \Sigma(x, x')\right)
\end{equation}

<p>
A very import special case of Gaussian processes is <a href="20211213085917-gaussian_markov_processes.html#ID-fbde252d-acb4-4a84-bcd9-ee865cdec64c">Gaussian Markov processes</a>
</p>


<div id="outline-container-org3ee6f74" class="outline-2">
<h2 id="org3ee6f74">Kernels</h2>
<div class="outline-text-2" id="text-org3ee6f74">
<p>
We often express the covariance function \(\Sigma(x, x')\) as a function of a <i>kernel</i> \(K(x,x')\)):
</p>

\begin{align*}
\displaystyle
 \Sigma(x,x') = K(x, x') + \sigma^{2}_{y}\;\mathbb{I}
\end{align*}

<ul class="org-ul">
<li><a href="20211129163720-squared_exponential_kernel.html#ID-338df7ae-048d-4a93-861b-80f75c3b887e">Squared exponential kernel</a></li>
<li><a href="20211129200726-gaussian_noise_kernel.html#ID-1a08425d-1fa8-4f9f-98d0-423b0d5c0991">Ornstein-Uhlenbeck kernel</a></li>
<li><a href="20211129201642-wiener_kernel.html#ID-dc211cf2-78b4-4269-91e8-fc88fb49def5">Wiener kernel</a></li>
<li><a href="20211206101631-periodic_kernel.html#ID-29e2f739-8736-4189-9e36-a706fd5ec574">Periodic kernel</a></li>
</ul>

<p>
We can combine kernels. The <a href="20211206102342-combine_kernels_by_multiplication.html#ID-16b13248-1128-4012-b8b4-44e51834bb6d">multiplication</a> of two covariance functions is a valid covariance functions, the <a href="20211206102419-combine_kernels_by_addition.html#ID-97dad3ac-e891-41ae-9a9d-3b4096fd781e">addition</a> of two correlation functions is a correlation function.
</p>
</div>

<div id="outline-container-orgb1ed2fc" class="outline-3">
<h3 id="orgb1ed2fc">References</h3>
<div class="outline-text-3" id="text-orgb1ed2fc">
<ul class="org-ul">
<li>The Kernel Cookbook (<a target='_blank' rel='noopener noreferrer' class='external' href="https://www.cs.toronto.edu/~duvenaud/cookbook/">David Duvenaud's website</a>)</li>
<li>Structure Discovery in Nonparametric Regression Through Compositional Search (<a target='_blank' rel='noopener noreferrer' class='external' href="https://arxiv.org/abs/1302.4922">ArXiV</a>)</li>
<li>Gaussian Processes for Machine Learning, Chapter 4: Covariance Functions (<a target='_blank' rel='noopener noreferrer' class='external' href="http://gaussianprocess.org/gpml/chapters/RW4.pdf">pdf</a>)</li>
<li>Kernel Design (<a target='_blank' rel='noopener noreferrer' class='external' href="http://gpss.cc/gpss15/talks/KernelDesign.pdf">slides of Nicolas Durrande's talk</a>)</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org0be07eb" class="outline-2">
<h2 id="org0be07eb">Sample</h2>
<div class="outline-text-2" id="text-org0be07eb">
<ul class="org-ul">
<li>How to <a href="20211206204210-sample_from_a_gaussian_process_predictive_distribution.html#ID-00ed041f-9d96-4d76-833f-39d1c2e40e70">Sample from a Gaussian Process predictive distribution</a></li>
<li>Practical implementation of Gaussian Process Regression (<a target='_blank' rel='noopener noreferrer' class='external' href="https://gregorygundersen.com/blog/2019/09/12/practical-gp-regression/">Gregory Undersen's blog</a>)</li>
<li>Gaussian Processes for Machine Learning, Chapter 2: Regression (<a target='_blank' rel='noopener noreferrer' class='external' href="https://gaussianprocess.org/gpml/chapters/RW2.pdf">pdf</a>)</li>
</ul>
</div>
</div>

<div id="outline-container-org86b46e3" class="outline-2">
<h2 id="org86b46e3">Learn</h2>
<div class="outline-text-2" id="text-org86b46e3">
<ul class="org-ul">
<li><a target='_blank' rel='noopener noreferrer' class='external' href="https://distill.pub/2019/visual-exploration-gaussian-processes/">Visual exploration of gaussian processes</a> is a very good introduction</li>
<li><a target='_blank' rel='noopener noreferrer' class='external' href="https://yugeten.github.io/posts/2019/09/GP/">Gaussian Process, not quite for dummies</a> is excellent, starts from gaussians to gaussian in high dimensions to get to gaussian process. One of the best things I've read on the topic.</li>
<li>cite:rasmussen2003 is a useful reference, but more advanced</li>
</ul>
</div>
</div>

<div id="outline-container-org43117d1" class="outline-2">
<h2 id="org43117d1">Use</h2>
<div class="outline-text-2" id="text-org43117d1">
<p>
Here is a list of libraries implementating different flavors of Gaussian processes. The catch is that gaussian processes can quick get computation-intensive.
</p>

<ul class="org-ul">
<li><a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/AaltoML/BayesNewton">BayesNewton</a> is written in JAX</li>
<li><a target='_blank' rel='noopener noreferrer' class='external' href="https://gpytorch.ai/">GPytorch</a> is built atop the Pytorch autodiff framework</li>
<li>PyMC3 also has an <a target='_blank' rel='noopener noreferrer' class='external' href="https://docs.pymc.io/en/v3/Gaussian_Processes.html">implementation of gaussian processes</a></li>
</ul>
</div>
</div>

<div id="outline-container-org9105d67" class="outline-2">
<h2 id="org9105d67">Links to this note</h2>
<div class="outline-text-2" id="text-org9105d67">
<ul class="org-ul">
<li><a href="./20220826152626-gpae.html">GPae</a></li>
<li><a href="./20211129200726-gaussian_noise_kernel.html">Ornstein-Uhlenbeck kernel</a></li>
<li><a href="./20211129163720-squared_exponential_kernel.html">Squared exponential kernel</a></li>
<li><a href="./20211125113956-my_digital_garden.html">Navigate linked notes</a></li>
<li><a href="./20220826141720-automatic_model_selection_with_aesara_rewrites.html">Automatic model selection with Aesara rewrites</a></li>
<li><a href="./20211129201642-wiener_kernel.html">Wiener kernel</a></li>
</ul>
</div>
</div>
</div>
</body>
</html>
