<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-09-05 Mon 18:22 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Random Walk Rosenbluth-Metropolis-Hastings in Aesara</title>
<meta name="author" content="RÃ©mi Louf" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../style.css" /><script data-goatcounter="https://thetypicalset.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Random Walk Rosenbluth-Metropolis-Hastings in Aesara</h1>
<p>
Right before I started working on <a href="file:///home/runner/projects/thetypicalset/org/blog/introducing-mcx.html">MCX</a> I wrote a simple benchmarks for PyTorch, Tensorflow and JAX on a very simple problem: using the random walk Rosenbluth-Metropolis-Hastings algorithm to sample from a mixture distribution. MCX was discontinued a bit more than a year ago, when I started working with a PPL based on <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aesara">Aesara</a>. So let me revisit this simple example using Aeasara!
</p>

<p>
The full code was added to the <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/rlouf/blog-benchmark-rwmetropolis/blob/master/aesara_sampler.py">repository</a>.
</p>

<div id="outline-container-orgb344614" class="outline-2">
<h2 id="orgb344614">Mixture model</h2>
<div class="outline-text-2" id="text-orgb344614">
<p>
<a href="file:///home/runner/projects/thetypicalset/org/blog/jax-parallel-mcmc.html">In the original blog post</a> I set to sample from a mixture distribution with 4 components. I had to write the corresponding log-probability density function by hand, i.e. without using a PPL. Implementing a mixture model in <code>Aesara</code> is straightforward. No need for a <code>Mixture</code> distribution (like in e.g. PyMC), you just write it like it is:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">import</span> aesara.tensor <span style="font-weight: bold;">as</span> at
<span style="font-weight: bold;">import</span> numpy <span style="font-weight: bold;">as</span> np

<span style="font-weight: bold; font-style: italic;">srng</span> = at.random.RandomStream(0)

<span style="font-weight: bold; font-style: italic;">loc</span> = np.array([-2, 0, 3.2, 2.5])
<span style="font-weight: bold; font-style: italic;">scale</span> = np.array([1.2, 1, 5, 2.8])
<span style="font-weight: bold; font-style: italic;">weights</span> = np.array([0.2, 0.3, 0.1, 0.4])

<span style="font-weight: bold; font-style: italic;">N_rv</span> = srng.normal(loc, scale, name=<span style="font-style: italic;">"N"</span>)
<span style="font-weight: bold; font-style: italic;">I_rv</span> = srng.categorical(weights, name=<span style="font-style: italic;">"I"</span>)
<span style="font-weight: bold; font-style: italic;">Y_rv</span> = N_rv[I_rv]
</pre>
</div>

<p>
We can generate forward samples from this model by compiling the model graph choosing <code>Y_rv</code> as an output:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">import</span> aesara

<span style="font-weight: bold; font-style: italic;">sample_fn</span> = aesara.function((), Y_rv)
<span style="font-weight: bold; font-style: italic;">samples</span> = [sample_fn() <span style="font-weight: bold;">for</span> _ <span style="font-weight: bold;">in</span> <span style="font-weight: bold;">range</span>(10000)]

<span style="font-weight: bold;">print</span>(samples[:10])
</pre>
</div>

<p>
If you are not familiar with Theano/Aesara, the <code>aesara.function</code> may surprise you. What does it do exactly? When you manipulate Aesara tensors, you are not manipulating numbers, but rather you are <i>describing the computation to perform on the inputs</i>. As a result, the result of an Aesara operation is a graph:
</p>

<div class="org-src-container">
<pre class="src src-python">aesara.dprint(Y_rv)
</pre>
</div>

<p>
<code>aesara.function</code> is therefore used to <i>compile</i> the graph into a function that can be executed. For that, we need to specify the inputs and outputs of the function. In this case there are no outputs, and the value of <code>Y_rv</code> is the output.
</p>

<p>
To compute the log-probability density function we can use <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aeppl">AePPL</a>'s <code>joint_logprob</code> function. AePPL transforms the Aesara model graph to get the graph that computes the model's joint logprob (see, working with computation graphs is nice!). We pass a dictionary that tells which value to associate with the random variables <code>Y_rv</code> and <code>I_rv</code>:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">from</span> aeppl <span style="font-weight: bold;">import</span> joint_logprob

<span style="font-weight: bold; font-style: italic;">y_vv</span> = Y_rv.clone()
<span style="font-weight: bold; font-style: italic;">i_vv</span> = I_rv.clone()
<span style="font-weight: bold; font-style: italic;">logprob</span> = joint_logprob({Y_rv: y_vv, I_rv: i_vv})

<span style="font-weight: bold;">print</span>(logprob.<span style="font-weight: bold;">eval</span>({y_vv: 10., i_vv: 3}))
</pre>
</div>

<pre class="example">
-6.452221131239579
</pre>


<p>
Here we do not really care about the values that <code>I_rv</code> takes, so we marginalize the log-probability density function over <code>I_rv</code>:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold; font-style: italic;">logprob</span> = []
<span style="font-weight: bold;">for</span> i <span style="font-weight: bold;">in</span> <span style="font-weight: bold;">range</span>(4):
    <span style="font-weight: bold; font-style: italic;">i_vv</span> = at.as_tensor(i, dtype=<span style="font-style: italic;">"int64"</span>)
    logprob.append(joint_logprob({Y_rv: y_vv, I_rv: i_vv}))
<span style="font-weight: bold; font-style: italic;">logprob</span> = at.stack(logprob, axis=0)
<span style="font-weight: bold; font-style: italic;">total_logprob</span> = at.logsumexp(at.log(weights) + logprob)

<span style="font-weight: bold;">print</span>(total_logprob.<span style="font-weight: bold;">eval</span>({y_vv: 10.}))
</pre>
</div>
</div>
</div>

<div id="outline-container-orgfd7e403" class="outline-2">
<h2 id="orgfd7e403">Implement the algorithm</h2>
<div class="outline-text-2" id="text-orgfd7e403">
<p>
The random walk Rosenbluth-Metropolis-Hasting algorithm is also straightforward to implement:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">def</span> <span style="font-weight: bold;">rw_metropolis_kernel</span>(srng, logprob_fn):
    <span style="font-style: italic;">"""Build the random walk Rosenbluth-Metropolis-Hastings (RNH) kernel."""</span>

    <span style="font-weight: bold;">def</span> <span style="font-weight: bold;">one_step</span>(position, logprob):
        <span style="font-style: italic;">"""Generate one sample using the random walk RMH algorithm.</span>

<span style="font-style: italic;">        Attributes</span>
<span style="font-style: italic;">        ----------</span>
<span style="font-style: italic;">        position:</span>
<span style="font-style: italic;">            The initial position.</span>
<span style="font-style: italic;">        logprob:</span>
<span style="font-style: italic;">            The initial value of the logprobability.</span>

<span style="font-style: italic;">        Returns</span>
<span style="font-style: italic;">        ------</span>
<span style="font-style: italic;">        The next positions and values of the logprobability.</span>

<span style="font-style: italic;">        """</span>
        <span style="font-weight: bold; font-style: italic;">move_proposal</span> = 0.1 * srng.normal(0, 1)
        <span style="font-weight: bold; font-style: italic;">proposal</span> = position + move_proposal
        <span style="font-weight: bold; font-style: italic;">proposal_logprob</span> = logprob_fn(proposal)

        <span style="font-weight: bold; font-style: italic;">log_uniform</span> = at.log(srng.uniform())
        <span style="font-weight: bold; font-style: italic;">do_accept</span> = log_uniform &lt; proposal_logprob - logprob

        <span style="font-weight: bold; font-style: italic;">position</span> = at.where(do_accept, proposal, position)
        <span style="font-weight: bold; font-style: italic;">logprob</span> = at.where(do_accept, proposal_logprob, logprob)

        <span style="font-weight: bold;">return</span> position, logprob

    <span style="font-weight: bold;">return</span> one_step
</pre>
</div>

<p>
Syntactically, <code>aesara.tensor</code> looks like a drop-in replacement to <code>numpy</code>. Remember, however, that these functions do not act on numbers but add an operation to an existing graph of computation. In particular, <code>logprob_fn</code> is a function that takes a graph (possibly a single variable), and returns the graph that computes the value of the log-probability density function.
</p>
</div>
</div>

<div id="outline-container-orga9a6459" class="outline-2">
<h2 id="orga9a6459">So, does it work?</h2>
<div class="outline-text-2" id="text-orga9a6459">
<p>
Let us sample 1000 chains concurrently for an increasing number of samples and compare the running time to NumPy's and JAX's:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">import</span> matplotlib.pylab <span style="font-weight: bold;">as</span> plt

<span style="font-weight: bold; font-style: italic;">n_chains</span> = [1, 10, 100, 1_000, 10_000, 100_000, 1_000_000]

<span style="font-weight: bold; font-style: italic;">fig</span> = plt.figure(figsize=(12, 8))
<span style="font-weight: bold; font-style: italic;">ax</span> = fig.add_subplot(111)
<span style="font-weight: bold;">for</span> key, values <span style="font-weight: bold;">in</span> chains_results.items():
    ax.plot(n_chains, values, label=key)
ax.set_xlabel(<span style="font-style: italic;">"Number of chains"</span>, fontsize=22, fontname=<span style="font-style: italic;">"Source Code Pro"</span>)
ax.set_ylabel(<span style="font-style: italic;">"Time (s)"</span>, fontsize=22, fontname=<span style="font-style: italic;">"Source Code Pro"</span>)
fig.suptitle(<span style="font-style: italic;">"Sampling 1,000 samples from a 4 components Gaussian mixture"</span>, fontsize=18, fontname=<span style="font-style: italic;">"Source Code Pro"</span>)

ax.set_xscale(<span style="font-style: italic;">'log'</span>)
ax.set_yscale(<span style="font-style: italic;">'log'</span>)
ax.spines[<span style="font-style: italic;">'right'</span>].set_visible(<span style="font-weight: bold; text-decoration: underline;">False</span>)
ax.spines[<span style="font-style: italic;">'top'</span>].set_visible(<span style="font-weight: bold; text-decoration: underline;">False</span>)
ax.yaxis.set_ticks_position(<span style="font-style: italic;">'left'</span>)
ax.xaxis.set_ticks_position(<span style="font-style: italic;">'bottom'</span>)

ax.legend(frameon=<span style="font-weight: bold; text-decoration: underline;">False</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-org2dabe4d" class="outline-2">
<h2 id="org2dabe4d">Perspectives</h2>
<div class="outline-text-2" id="text-org2dabe4d">
<p>
Aesara is still young and holds many promises for the future, <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aesara/issues">come help us</a>! Here is what you can expect to change with this example in the near future:
</p>

<p>
<b><b>Maginalize automatically.</b></b>  <code>AePPL</code> will soon allow to automatically marginalize over discrete random variable (see <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aeppl/issues/21">related issue</a>).
</p>

<p>
<b><b>Vectorize computation.</b></b> The implementation for the multiple chain sampler is currently close to NumPy's for performance reasons, but you should soon be able to write the kernel for a single chain, and use the equivalent of <code>np.vectorize</code> or <code>jax.vmap</code> to vectorize the computation (see <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aesara/issues/695">related issue</a>).
</p>

<p>
<b><b>Work with different backends.</b></b> You will soon be able to compile this example using Aesara's JAX backend and Numba backend (<a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aesara/tree/main/aesara/link">work in progress, you can already try it!</a>). This means you will be able to interact with different ecosystems and leverage the strengths of different compilers / hardware devices with the <i>same model expression</i> in python. This also means that your model code is more future-proof as you can make the backend move under it.
</p>

<p>
<b><b>Build samplers automatically.</b></b> <a target='_blank' rel='noopener noreferrer' class='external' href="https://github.com/aesara-devs/aemcmc">AeMCMC</a> analyzes your model graph and builds an efficient sampler for it.
</p>
</div>
</div>
</div>
</body>
</html>
