<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-12-09 Fri 10:27 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Shape semantics for random variables in Aesara</title>
<meta name="author" content="RÃ©mi Louf" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="../style.css" /><script data-goatcounter="https://thetypicalset.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Shape semantics for random variables in Aesara</h1>
<p>
<b><b>Although this contains useful information, this post is a draft and will probably be integrated to Aesara's documentation</b></b>
</p>

<div id="outline-container-org9d6182e" class="outline-2">
<h2 id="org9d6182e">Random variables in Aesara</h2>
<div class="outline-text-2" id="text-org9d6182e">
<p>
Random variables are represented in <a href="../20220729163627-aesara.html#ID-5a5e87b1-558c-43db-ad38-32a073b10351">Aesara</a> with the <code>RandomVariable</code> operator, which corresponds to the following mathematical function:
</p>

<p>
\[
\operatorname{RandomVariable}: \Omega \times \Theta \to E
\]
</p>

<p>
Were \(\Omega\) is the set of available RNG seeds, \(\Theta\) the parameter space. \(E\) is the state space, which corresponds to the support of the corresponding distribution. Given a random seed and parameter values, the operator returns a <b>realization</b> of the random variable it represents, i.e. element of \(E\).
</p>

<p>
The recommended way to use random variables in Aesara is via the <code>RandomStream</code> interface, which automatically seeds the random functions. Here, <code>srng.normal</code> defines a single, normally-distributed, random variable:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)
<span style="color: #DFAF8F;">x_rv</span> = srng.normal(0, 1)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(x_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>())
</pre>
</div>

<pre class="example">
1.4436909546981256
</pre>


<p>
The shape of the output of the random functions depends on three things:
</p>
<ul class="org-ul">
<li>The <i>support shape</i> of the random variable;</li>
<li>Broadcasting rules between the parameters of the random variable's distribution;</li>
<li>The <code>size</code> parameter passed to the random function.</li>
</ul>

<p>
In this document we will make explaine the semantics of shape in Aesara, and what they represent.
</p>
</div>
</div>

<div id="outline-container-org7da8370" class="outline-2">
<h2 id="org7da8370">The support shape</h2>
<div class="outline-text-2" id="text-org7da8370">
<p>
The dimensionality of the parameter space and the sample space differs depending on the distribution. For instance, the normal distribution is parametrized by \(\mu \in \mathbb{R}\) and \(\sigma \in \mathbb{R}^+\) and the realizations of the corresponding random variables are scalars \(\in \mathbb{R}\).
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">mu</span> = 0
<span style="color: #DFAF8F;">sigma</span> = 1
<span style="color: #DFAF8F;">x_rv</span> = srng.normal(mu, sigma)
<span style="color: #DFAF8F;">sample</span> = x_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()

<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample value: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"support shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample value: 1.4436909546981256
support shape: ()
</pre>


<p>
We say that the support shape of <code>normal</code> is <code>()</code>. The Dirichlet distribution is slightly more complicated: it is parametrized by a vector \(\boldsymbol{\alpha} \in \mathbb{R}^k\) and its realizations are vectors in the k-unit simplex \(\operatorname{\Delta}^k\):
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">alpha</span> = [1., 3., 4.]
<span style="color: #DFAF8F;">x_rv</span> = srng.dirichlet(alpha)
<span style="color: #DFAF8F;">sample</span> = x_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()

<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample value: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"support shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample value: [0.39086221 0.17265609 0.43648169]
support shape: (3,)
</pre>


<p>
The support shape of <code>dirichlet</code> is <code>(k,)</code>, with <code>k</code> the length of its parameter \(\alpha\). The multinomial is another interesting example because the dimensionality of its parameters; it is parametrized by a probability vector \(\boldsymbol{p} \in \Delta^k\), a number of trials \(n \in \mathbb{N}\) and returns a vector in \(\mathbb{N}^k\):
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">n</span> = 10
<span style="color: #DFAF8F;">p</span> = [.1, .3, .6]
<span style="color: #DFAF8F;">x_rv</span> = srng.multinomial(n, p)
<span style="color: #DFAF8F;">sample</span> = x_rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()

<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample value: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"support shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample value: [3 2 5]
support shape: (3,)
</pre>


<p>
The support shape of <code>multinomial</code> is <code>(k,)</code> with <code>k</code> the length of the probability vector \(p\). Here we have only considered random variables with a 0- or 1-dimensional sample space, but it can obviously be more complicated. The random variable with a <a target='_blank' rel='noopener noreferrer' class='external' href="https://en.wikipedia.org/wiki/Wishart_distribution">Wishart density</a> is a function that maps to \(\mathbb{R}^{n \times m}\), and the corresponding support shape is thus <code>(n,m)</code>.
</p>

<p>
The support shape and how it relates to the shape of the parameters is explicited in <a target='_blank' rel='noopener noreferrer' class='external' href="https://aesara.readthedocs.io/en/latest/library/tensor/random/basic.html">the documentation</a>, where we attach a <code>signature</code> string to each random variable (these are <a target='_blank' rel='noopener noreferrer' class='external' href="https://numpy.org/doc/stable/reference/c-api/generalized-ufuncs.html">gufunc</a>-like signatures). For instance, for the previous examples we have:
</p>

<ul class="org-ul">
<li>Normal: <code>(), () -&gt; ()</code></li>
<li>Dirichlet: <code>(n) -&gt; (n)</code></li>
<li>Multinomial: <code>(), (n) -&gt; (n)</code></li>
</ul>
</div>
</div>

<div id="outline-container-orgf1ce527" class="outline-2">
<h2 id="orgf1ce527">The batch shape</h2>
<div class="outline-text-2" id="text-orgf1ce527">
<p>
We just saw how to define a single random variables with different distributions, and how the choice of distribution determined the <i>support shape</i>. In many realistic settings, however, we would like to define several independently distributed random variables at once. Aesara provides two mechanisms to do so: broadcasting of the parameters, and the <code>size</code> parameter. The shape induced by this mechanism is called the <i>batch shape</i>.
</p>
</div>

<div id="outline-container-org6663ac1" class="outline-3">
<h3 id="org6663ac1">Batching by broadcasting</h3>
<div class="outline-text-3" id="text-org6663ac1">
<p>
Say we want a sample from three independent, normally distributed,  random variables with a mean of \(0\), \(3\) and \(5\) respectively. One (cumbersome) way to achieve this is:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream()
<span style="color: #DFAF8F;">rv_0</span> = srng.normal(0, 1)
<span style="color: #DFAF8F;">rv_3</span> = srng.normal(3, 1)
<span style="color: #DFAF8F;">rv_5</span> = srng.normal(5, 1)
<span style="color: #DFAF8F;">rv</span> = at.stack([rv_0, rv_3, rv_5])

<span style="color: #DFAF8F;">sample</span> = rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample value: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample value: [1.65040785 1.76749492 5.86773357]
sample shape: (3,)
</pre>


<p>
To simplify this common operation, we can pass arrays as parameters to Aesara's <code>RandomVariable</code>, and the <code>Op</code> will use NumPy broadcasting rules to return an array of independent random variables:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">mean</span> = np.array([0, 3, 5])
<span style="color: #DFAF8F;">rv</span> = srng.normal(mean, 1)

<span style="color: #DFAF8F;">sample</span> = rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample values: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample values: [1.44369095 2.10405402 5.73595567]
sample shape: (3,)
</pre>


<p>
In this case the <i>batch shape</i> is also  <code>(3,)</code>; it is the shape of the tensor that contains random variables that are independently distributed and whose distribution belong to the same family.
</p>

<p>
In this case, <code>srng.normal(mean, 1)</code> implicitly represents 3 independent random variables; if it helps one can imagine it is a shortcut for the first code block of this section.
</p>

<p>
We can also use arrays for the standard deviation in this case. Standard broadcasting rules apply to determine the batch shape. For instance, the following fails with a shape mismatch error:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">mean</span> = np.array([0, 3, 5])
<span style="color: #DFAF8F;">sigma</span> = np.array([1, 2])
<span style="color: #DFAF8F;">rv</span> = srng.normal(mean, sigma)

<span style="color: #F0DFAF; font-weight: bold;">try</span>:
    rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
<span style="color: #F0DFAF; font-weight: bold;">except</span> <span style="color: #7CB8BB;">ValueError</span> <span style="color: #F0DFAF; font-weight: bold;">as</span> err:
    <span style="color: #F0DFAF; font-weight: bold;">print</span>(err)
</pre>
</div>

<pre class="example" id="org96e6e4d">
shape mismatch: objects cannot be broadcast to a single shape
Apply node that caused the error: normal_rv{0, (0, 0), floatX, True}(RandomGeneratorSharedVariable(&lt;Generator(PCG64) at 0x7FDB97DFD200&gt;), TensorConstant{[]}, TensorConstant{11}, TensorConstant{[0 3 5]}, TensorConstant{[1 2]})
Toposort index: 0
Inputs types: [RandomGeneratorType, TensorType(int64, (0,)), TensorType(int64, ()), TensorType(int64, (3,)), TensorType(int64, (2,))]
Inputs shapes: ['No shapes', (0,), (), (3,), (2,)]
Inputs strides: ['No strides', (8,), (), (8,), (8,)]
Inputs values: [Generator(PCG64) at 0x7FDB97DFD200, array([], dtype=int64), array(11), array([0, 3, 5]), array([1, 2])]
Outputs clients: [['output'], ['output']]

HINT: Re-running with most Aesara optimizations disabled could provide a back-trace showing when this node was created. This can be done by setting the Aesara flag 'optimizer=fast_compile'. If that does not work, Aesara optimizations can be disabled with 'optimizer=None'.
HINT: Use the Aesara flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node.
</pre>

<p>
Indeed <code>mean</code> and <code>sigma</code> cannot be broadcast together:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">mean</span> = np.array([0, 3, 5])
<span style="color: #DFAF8F;">sigma</span> = np.array([1, 2])
<span style="color: #F0DFAF; font-weight: bold;">try</span>:
    np.broadcast(mean, sigma)  <span style="color: #5F7F5F;"># </span><span style="color: #7F9F7F;">error</span>
<span style="color: #F0DFAF; font-weight: bold;">except</span> <span style="color: #7CB8BB;">ValueError</span> <span style="color: #F0DFAF; font-weight: bold;">as</span> err:
    <span style="color: #F0DFAF; font-weight: bold;">print</span>(err)
</pre>
</div>

<pre class="example">
shape mismatch: objects cannot be broadcast to a single shape
</pre>


<p>
<code>np.broadcast(mean, sigma)</code> gives us the batch shape:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">mean</span> = np.array([0, 3, 5])
<span style="color: #DFAF8F;">sigma</span> = np.array([1, 2, 7])
<span style="color: #F0DFAF; font-weight: bold;">print</span>(np.broadcast(mean, sigma).shape)
</pre>
</div>

<pre class="example">
(3,)
</pre>


<p>
Indeed:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">mean</span> = np.array([0, 3, 5])
<span style="color: #DFAF8F;">sigma</span> = np.array([1, 2, 3])
<span style="color: #DFAF8F;">rv</span> = srng.normal(mean, sigma)

<span style="color: #DFAF8F;">sample</span> = rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample values: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"batch shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample values: [1.44369095 1.20810805 7.20786701]
batch shape: (3,)
</pre>


<p>
Since the <code>RandomVariable</code> represents a batch of random variables, we will call the resulting shape the <b>batch shape</b>.
</p>

<p>
The normal distribution is fairly simple since its parameters and realization are 1-dimensional. Let take our dirichlet example:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">alpha</span> = np.array([[1., 2., 4.], [3., 5., 7.]])
<span style="color: #DFAF8F;">rv</span> = srng.dirichlet(alpha)
<span style="color: #DFAF8F;">sample</span> = rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()

<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample values: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample values: [[0.42615878 0.09794332 0.4758979 ]
 [0.15408529 0.34781447 0.49810024]]
sample shape: (2, 3)
</pre>


<p>
Which is equivalent to:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">rv1</span> = srng.dirichlet([1., 2., 4.])
<span style="color: #DFAF8F;">rv2</span> = srng.dirichlet([3., 5., 7.])
<span style="color: #DFAF8F;">rv</span> = at.stack([rv1, rv2])
<span style="color: #DFAF8F;">sample</span> = rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()

<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample values: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample values: [[0.42615878 0.09794332 0.4758979 ]
 [0.27582652 0.02985376 0.69431972]]
sample shape: (2, 3)
</pre>


<p>
So we have the simple formula; if <code>support_shape</code> and <code>batch_shape</code> are tuples, then:
</p>

<blockquote>
<p>
sample<sub>shape</sub> = batch<sub>shape</sub> + support<sub>shape</sub>
</p>
</blockquote>
</div>
</div>

<div id="outline-container-org2120831" class="outline-3">
<h3 id="org2120831">Expanding to create identically distributed random variables</h3>
<div class="outline-text-3" id="text-org2120831">
<p>
We also frequently need to define iiid random variables. We can define 3 normally-distributed random variables with mean 0 and variance 1 with:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">mean</span> = np.zeros(3)
<span style="color: #DFAF8F;">rv</span> = srng.normal(mean, 1)

<span style="color: #DFAF8F;">sample</span> = rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample values: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample values: [ 1.44369095 -0.89594598  0.73595567]
sample shape: (3,)
</pre>


<p>
But there is a shortcut: the <code>size</code> parameter of the distribution. In the following code, <code>size</code> allows us to define the same 3 random variables as above in a more concise way:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">rv</span> = srng.normal(0, 1, size=3)

<span style="color: #DFAF8F;">sample</span> = rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample values: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample values: [ 1.44369095 -0.89594598  0.73595567]
sample shape: (3,)
</pre>


<p>
We can of course do the same thing with the dirichlet distribution:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">rv</span> = srng.dirichlet([1, 3, 5], size=3)

<span style="color: #DFAF8F;">sample</span> = rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample values: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample values: [[0.34934376 0.15431609 0.49634016]
 [0.16080299 0.37886972 0.4603273 ]
 [0.21030357 0.42525361 0.36444282]]
sample shape: (3, 3)
</pre>


<p>
Since we are still talking about independent random variables, <code>batch</code> refers indistinctly to identifically distributed or differently distributed random variables.
</p>
</div>
</div>

<div id="outline-container-org5631597" class="outline-3">
<h3 id="org5631597">Broadcasting and expanding</h3>
<div class="outline-text-3" id="text-org5631597">
<p>
<b>Size corresponds to the batch shape</b>
</p>

<p>
<i>(show an example where broadcasting and using <code>size</code> breaks)</i>
</p>

<p>
It is possible to vectorize and batch at the same time. Note that <code>size</code> and that vectorized shape must be broadcastable
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #F0DFAF; font-weight: bold;">import</span> aesara.tensor <span style="color: #F0DFAF; font-weight: bold;">as</span> at
<span style="color: #F0DFAF; font-weight: bold;">import</span> numpy <span style="color: #F0DFAF; font-weight: bold;">as</span> np

<span style="color: #DFAF8F;">srng</span> = at.random.RandomStream(0)

<span style="color: #DFAF8F;">mean</span> = np.array([0, 3, 5])
<span style="color: #DFAF8F;">sigma</span> = np.array([1, 2, 3])
<span style="color: #DFAF8F;">rv</span> = srng.normal(mean, sigma, size=(2, 2, 3))

<span style="color: #DFAF8F;">sample</span> = rv.<span style="color: #DCDCCC; font-weight: bold;">eval</span>()
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"sample values: {sample}"</span>)
<span style="color: #F0DFAF; font-weight: bold;">print</span>(f<span style="color: #CC9393;">"batch shape: {sample.shape}"</span>)
</pre>
</div>

<pre class="example">
sample values: [[[1.44369095e+00 1.20810805e+00 7.20786701e+00]
  [5.87704041e-03 4.70676358e+00 5.48284410e+00]]

 [[8.19314690e-01 4.61131137e+00 5.65270195e+00]
  [9.70078743e-01 1.52177388e+00 6.78043377e+00]]]
batch shape: (2, 2, 3)
</pre>


<p>
where <code>np.broadcast(mean, sigma).shape</code> must correspond to the last dimensions of <code>size</code>. Or in other words, the sample shape is <code>np.broadcast_shapes(np.broadcast(mean, sigma).shape, size)</code> if this does not raise an error.
</p>

<p>
It IS really simple:
</p>

<p>
<code>sample_shape = np.broadcast_shapes(np.broadcast(*args), size)</code>
</p>
</div>
</div>
</div>


<div id="outline-container-org72ccbc6" class="outline-2">
<h2 id="org72ccbc6">Summary</h2>
<div class="outline-text-2" id="text-org72ccbc6">
<p>
The shape of random tensors in <a href="../20220729163627-aesara.html#ID-5a5e87b1-558c-43db-ad38-32a073b10351">Aesara</a> is partitioned in semantically different pieces, that refer to the shape of \(E\), i.e. the shape of draws we get:
</p>
<ul class="org-ul">
<li>The <b>support shape</b> corresponds to the shape of one element in \(E\), the support of the distribution;</li>
<li>The <b>batch shape</b> is the number \(N\) of independent random variables \(X_i: \Omega \to E\) where \(i \in \left\{ 1 \dots N\right\}\); These can be identically or differently distributed.</li>
<li><code>RandomVariable</code> creates <i>differently distributed</i> random variables by passing different values of parameters to the operators. Broadcasting rules apply, and the <b>batch shape</b> (i.e. number of differently distributed random variables) is inferred from these broadcasting rules.</li>
<li><code>RandomVariable</code> creates <i>identically distributed</i> random variables via the <code>size</code> keyword argument. There is a level of indirection here; the shape specified by <code>size</code> must broadcast with the shape of the broadcasted arguments. So if the latter is <code>(a, b)</code>, to define <code>c</code> identically distributed RVs one must set <code>size</code> to <code>(c, a, b)</code>.</li>
<li>The shape of the array of random variables is given by <code>sample_shape = batch_shape + support_shape</code></li>
</ul>
</div>
</div>
</div>
</body>
</html>