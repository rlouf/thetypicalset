<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-12-01 Thu 09:57 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Hidden Markov Models in Aesara</title>
<meta name="author" content="RÃ©mi Louf" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="style.css" /><script data-goatcounter="https://thetypicalset.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Hidden Markov Models in Aesara</h1>
<p>
Implementing Hidden Markov Models is not easy in the existing probabilistic programming libraries in python, as they are unable to reconstruct the logprob because of the loops. In <a href="20220729163627-aesara.html#ID-5a5e87b1-558c-43db-ad38-32a073b10351">Aesara</a> we just implement it like it is, as with <a href="20220824141346-mixture_models_in_aesara.html#ID-0b066c70-be98-4a81-8565-d6da26924416">Mixture models</a>.
</p>

<p>
Let us consider a hidden Markov model with \(N_t\) time steps and \(M_t\) possible states. The observation model is such that:
</p>

\begin{align*}
(Y_t | S_t = c) &\sim \operatorname{N}\left(\mu_{c}, \sigma_{c}\right)\\
S_t &\sim  \operatorname{Categorical}\left(\Gamma_0\right)
\end{align*}

<p>
The hidden state sequence is defined by the Markov relation:
</p>

\begin{equation*}
P(S_t|S_{t-1}) = \Gamma
\end{equation*}

<p>
Where the transition matrix \(\Gamma\) is assumed to be constant.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">import</span> aesara
<span style="font-weight: bold;">import</span> aesara.tensor <span style="font-weight: bold;">as</span> at

<span style="font-weight: bold; font-style: italic;">srng</span> = at.random.RandomStream(0)

<span style="font-weight: bold; font-style: italic;">N_tt</span> = at.iscalar(<span style="font-style: italic;">"N"</span>)
<span style="font-weight: bold; font-style: italic;">M_tt</span> = at.iscalar(<span style="font-style: italic;">"M"</span>)
<span style="font-weight: bold; font-style: italic;">Gamma_rv</span> = srng.dirichlet(at.ones((M_tt, M_tt)), name=<span style="font-style: italic;">"Gamma"</span>)

<span style="font-weight: bold; font-style: italic;">mu_tt</span> = at.vector(<span style="font-style: italic;">"mus"</span>)
<span style="font-weight: bold; font-style: italic;">sigma_tt</span> = 1.

<span style="font-weight: bold;">def</span> <span style="font-weight: bold;">scan_fn</span>(Gamma_t):
    <span style="font-weight: bold; font-style: italic;">S_t</span> = srng.categorical(Gamma_t[0], name=<span style="font-style: italic;">"S_t"</span>)
    <span style="font-weight: bold; font-style: italic;">Y_t</span> = srng.normal(mu_tt[S_t], sigma_tt, name=<span style="font-style: italic;">"Y_t"</span>)
    <span style="font-weight: bold;">return</span> Y_t, S_t

(Y_rv, S_rv), <span style="font-weight: bold; font-style: italic;">updates</span> = aesara.scan(
    fn=scan_fn,
    non_sequences=[Gamma_rv],
    outputs_info=[{}, {}],
    strict=<span style="font-weight: bold; text-decoration: underline;">True</span>,
    n_steps=N_tt
)

<span style="font-weight: bold; font-style: italic;">sample_fn</span> = aesara.function((N_tt, M_tt, mu_tt), (Y_rv, S_rv), updates=updates)
<span style="font-weight: bold;">print</span>(sample_fn(10, 2, [-10, 10]))
</pre>
</div>

<p>
Thanks to AePPL we can compute this models' logprobability function easily:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">from</span> aeppl <span style="font-weight: bold;">import</span> joint_logprob
<span style="font-weight: bold;">import</span> numpy <span style="font-weight: bold;">as</span> np

<span style="font-weight: bold; font-style: italic;">y_vv</span> = Y_rv.clone()
<span style="font-weight: bold; font-style: italic;">s_vv</span> = S_rv.clone()
<span style="font-weight: bold; font-style: italic;">Gamma_vv</span> = Gamma_rv.clone()

<span style="font-weight: bold; font-style: italic;">values</span> = {
    y_vv: np.random.normal(0, 1., size=10),
    s_vv: np.ones(10, dtype=<span style="font-style: italic;">"int"</span>),
    M_tt: 2,
    N_tt: 10,
    mu_tt: [-1., 1.],
    Gamma_vv:[[.5, .5], [.5, .5]],
}

<span style="font-weight: bold; font-style: italic;">logprob</span> = joint_logprob({Y_rv: y_vv, S_rv: s_vv, Gamma_rv: Gamma_vv})
<span style="font-weight: bold; font-style: italic;">logprob_fn</span> = aesara.function(<span style="font-weight: bold;">list</span>(values.keys()), logprob)
<span style="font-weight: bold;">print</span>(logprob_fn(*values.values()))
</pre>
</div>

<div id="outline-container-org6aaf698" class="outline-2">
<h2 id="org6aaf698">Links to this note</h2>
</div>
</div>
</body>
</html>