:PROPERTIES:
:ID:       f2d80a0e-47f7-4531-a654-8343c72dd962
:END:
#+title: Gaussian process
#+filetags: :inprogress:machine_learning:statistics:public:

#+PROPERTY: header-args:latex :results raw :exports results

- tags :: [[id:accc4a58-2f96-42da-a43d-c8140996d0d3][Probability distribution]]

We have the follow impractical definition:

#+begin_quote
A Gaussian process is a collection of random variables, any finite number of which have consistent Gaussian distributions.
#+end_quote

It is completely defined by its mean function $m(x)$ and covariance function $\Sigma(x, x')$. We write:

#+begin_src latex
\begin{equation}
  f(x) \sim \mathcal{G}\left(m(x), \Sigma(x, x')\right)
\end{equation}
#+end_src

#+RESULTS:
\begin{equation}
  f(x) \sim \mathcal{G}\left(m(x), \Sigma(x, x')\right)
\end{equation}

A very import special case of Gaussian processes is [[id:fbde252d-acb4-4a84-bcd9-ee865cdec64c][Gaussian Markov processes]]


* Kernels

We often express the covariance function $\Sigma(x, x')$ as a function of a /kernel/ $K(x,x')$):

#+begin_src latex
\begin{align*}
\displaystyle
 \Sigma(x,x') = K(x, x') + \;\mathbb{I}
\end{align*}
#+end_src

#+RESULTS:
\begin{align*}
\displaystyle
 \Sigma(x,x') = K(x, x') + \sigma^{2}_{y}\;\mathbb{I}
\end{align*}

- [[id:338df7ae-048d-4a93-861b-80f75c3b887e][Squared exponential kernel]]
- [[id:1a08425d-1fa8-4f9f-98d0-423b0d5c0991][Ornstein-Uhlenbeck kernel]]
- [[id:dc211cf2-78b4-4269-91e8-fc88fb49def5][Wiener kernel]]
- [[id:29e2f739-8736-4189-9e36-a706fd5ec574][Periodic kernel]]

We can combine kernels. The [[id:16b13248-1128-4012-b8b4-44e51834bb6d][multiplication]] of two covariance functions is a valid covariance functions, the [[id:97dad3ac-e891-41ae-9a9d-3b4096fd781e][addition]] of two correlation functions is a correlation function.


* Sample

How to [[id:00ed041f-9d96-4d76-833f-39d1c2e40e70][Sample from a Gaussian Process predictive distribution]]

* Learn

- [[https://distill.pub/2019/visual-exploration-gaussian-processes/][Visual exploration of gaussian processes]] is a very good introduction
- [[https://yugeten.github.io/posts/2019/09/GP/][Gaussian Process, not quite for dummies]] is excellent, starts from gaussians to gaussian in high dimensions to get to gaussian process. One of the best things I've read on the topic.
- cite:rasmussen2003 is a useful reference, but more advanced

* Use

Here is a list of libraries implementating different flavors of Gaussian processes. The catch is that gaussian processes can quick get computation-intensive.

- [[https://github.com/AaltoML/BayesNewton][BayesNewton]] is written in JAX
- [[https://gpytorch.ai/][GPytorch]] is built atop the Pytorch autodiff framework
- PyMC3 also has an [[https://docs.pymc.io/en/v3/Gaussian_Processes.html][implementation of gaussian processes]]
