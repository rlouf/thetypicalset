:PROPERTIES:
:ID:       fb76fc82-2653-4aa7-bb62-cd5ec749531a
:END:
#+title: Gibbs sampling

Gibbs sampling is a family of [[id:5acc4f0f-417e-424f-95a5-1c95e7e822ff][Markov Chain Monte Carlo]] algorithm where we conditionally sample from each parameter while holding the others fixed, successively.

Let us briefly explain where it comes from and the motivations behind it. Let us consider a response variable $\bb{Y}$, feature matrix $X$ and a model with parameter $\boldsymbol{\beta}$ so the likelihood of the data given the model and parameter values is given by

$$
P\left(Y | X, \beta\right)
$$

Given a test point $x_*$ we are usually interested in the following predictive distribution:

$$
P\left(y_* | Y, X, \beta, x_*\right)
$$

Which can be written as:

$$
P\left(y_* | Y, X, x_*\right) = \int P(y_*| \beta, x_*) P(\beta|Y, X) \mathrm{d} \beta
$$

- Bernoulli logit regression:  [[id:16338bc2-222c-4acf-aa28-38b951dfcb89][Polya-Gamma augmentation]]
- Negative Binomial logit regression:  [[id:16338bc2-222c-4acf-aa28-38b951dfcb89][Polya-Gamma augmentation]]
- Horsehoe prior using the [[id:45ccc897-f07c-4adc-9142-9ae8870fbddc][inverse-gamma expansion of the Half-Cauchy distribution]]
