#+TITLE: Estimer le report des voix aux présidentielles
#+DATE: <2022-06-13 Mon>

Cet article fait suite au [[https://github.com/laurentperrinet/2022-05-04_transfert-des-voix/blob/main/2022-06-08_transfert-des-voix.ipynb][travail de Laurent Perrinet]] sur les reports de voix entre le premier et le deuxième tour des élections présidentielles en 2022. La démarche de ce travail est intéressante (et autant que je sache originale) : elle consiste à prendre les résultats des élections au niveau des bureaux de vote aux deux tours, et essayer d'estimer une matrice de transition i.e. la probabilité que quelqu'un ayant voté pour X (par exemple Fabien Roussel) vote pour Y (par exemple Marine Le Pen) au second tour.

Le modèle utilisé est déterministe. Il est implémenté avec PyTorch:

#+begin_src python
import torch
from torch.utils.data import TensorDataset, DataLoader, random_split
import torch.nn.functional as F

torch.set_default_tensor_type("torch.FloatTensor")

class TransfertVoix(torch.nn.Module):
    def __init__(self, N_1er, N_2eme):#, device=None):
        super(TransfertVoix, self).__init__()
        self.lin = torch.nn.Linear(N_2eme, N_1er, bias=False)

    def forward(self, p_1):
        M = torch.softmax(self.lin.weight, axis=1)
        p_2_pred = torch.matmul(p_1, M)
        return p_2_pred
#+end_src

A première lecture des résultats et au vu du modèle ci-dessus plusieurs pistes d'amélioration me viennent en tête:
1. L'auteur montre les corrélations entre le vote Mélenchon au premier tour, et celui de Macron au second tour. Les distributions marginales sont très étalées. Je m'attend à une variabilité encore plus grande pour les candidats avec un score moindre. Cette variabilité peut avoir un effet non-négligeable sur les résultats; je suis par exemple surpris des forts reports vers Le Pen calculés pour Arthaud, Poutou et Roussel. Ce n'est pas à exclure, certes, mais je pense que l'on bénéficierait d'une approche bayésienne et bénéficier d'une marge d'erreur sur ces résultats;
2. L'hypothèse d'un report uniforme sur tout le territoire me parait également osée. On devrait envisager un modèle hiérarchique;
3. Les sondages de sortie d'urne peuvent servir pour définir le prior (hyperprior dans le cas d'un modèle hiérarchique).

#+begin_src python :session :result silent
import os
import numpy as np
import pandas as pd
#+end_src

#+RESULTS:

* Les données

On se placera ici à l'échelle de la circonscription législative. Le découpage à l'échelle du bureau de vote est intéressant, mais le but implicite de cette étude est de donner une idée des reports de voix pour le second tour des législatives 2022. J'utilise ici le code de [[https://github.com/laurentperrinet/2022-05-04_transfert-des-voix/blob/main/2022-06-08_transfert-des-voix.ipynb][Laurent Perrinet]] en le modifiant (les erreurs éventuelles sont de mon fait).

** Premier tour


#+begin_src python :session :results silent
fname = '/tmp/T1.xlsx'

if not os.path.isfile(fname):
    url = "https://www.data.gouv.fr/fr/datasets/r/1a35594a-99f2-4257-87e0-ec2f55039276"
    import urllib.request
    urllib.request.urlretrieve(url, fname)

T1 = pd.read_excel(fname)
#+end_src


#+begin_src python :session
T1.tail()
#+end_src

#+RESULTS:
:     Code du département           Libellé du département  Code de la circonscription Libellé de la circonscription Etat saisie  ...    Unnamed: 98  Unnamed: 99  Unnamed: 100  Unnamed: 101  Unnamed: 102
: 572                  ZZ  Français établis hors de France                           7          7ème circonscription     Complet  ...  DUPONT-AIGNAN      Nicolas           639          0.52          1.23
: 573                  ZZ  Français établis hors de France                           8          8ème circonscription     Complet  ...  DUPONT-AIGNAN      Nicolas           300          0.23          1.28
: 574                  ZZ  Français établis hors de France                           9          9ème circonscription     Complet  ...  DUPONT-AIGNAN      Nicolas           381          0.31          0.97
: 575                  ZZ  Français établis hors de France                          10         10ème circonscription     Complet  ...  DUPONT-AIGNAN      Nicolas           530          0.51          1.33
: 576                  ZZ  Français établis hors de France                          11         11ème circonscription     Complet  ...  DUPONT-AIGNAN      Nicolas           595          0.60          1.58
:
: [5 rows x 103 columns]

#+begin_src python :session
df_1 = T1[['Nuls', 'Blancs', 'Abstentions']].copy()
df_1["Non exprimés"] =  df_1['Nuls'] + df_1['Blancs'] + df_1['Abstentions']
df_1 = df_1[["Non exprimés"]].copy()
T1['Code de la circonscription'] = T1['Code de la circonscription'].apply(str)
#df_1['circonscription'] = T1['Code du département'] + T1['Code de la circonscription']
df_1.head()
#+end_src

#+RESULTS:
:    Non exprimés
: 0         20139
: 1         21636
: 2         21581
: 3         21599
: 4         20130


#+begin_src python :session :results silent
col_start = 21
col_par_cdt = 7
candidats = T1.iloc[0][col_start::col_par_cdt]

for i_candidat, candidat in enumerate(candidats):
    i_col = col_start + i_candidat*col_par_cdt + 2
    print('# colonne', i_col, ' résultats=', T1.iloc[:, i_col].values)
    df_1[candidat] = T1.iloc[:, i_col].values
#+end_src


Let's check the results by plotting the distribution of votes:

#+begin_src python :session :results file :exports both :var filename=(org-babel-temp-file "figure" ".png")
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(13, 5))
k = df_1.sum()/df_1.sum().sum()
ax = k.plot.bar(ax=ax)
ax.set_xlabel('Choix 1er tour')
ax.set_ylabel('Pourcentage');
plt.savefig(filename, bbox_inches="tight")
filename
#+end_src


#+RESULTS:
[[file:/tmp/babel-XyHH31/figureFbqdwF.png]]

** Deuxième tour

#+begin_src python :session :results silent
fname = '/tmp/T2.xlsx'

if not os.path.isfile(fname):
    url = "https://www.data.gouv.fr/fr/datasets/r/5eacdbc7-b1a2-440c-8eef-09c8bfb87609"
    import urllib.request
    urllib.request.urlretrieve(url, fname)

T2 = pd.read_excel(fname)
#+end_src


#+begin_src python :session
T2.tail()
#+end_src

#+RESULTS:
:     Code du département           Libellé du département  Code de la circonscription Libellé de la circonscription Etat saisie  Inscrits  ...  Unnamed: 27  Unnamed: 28  Unnamed: 29  Unnamed: 30  Unnamed: 31  Unnamed: 32
: 572                  ZZ  Français établis hors de France                           7          7ème circonscription     Complet    122145  ...            F       LE PEN       Marine         4987         4.08         8.58
: 573                  ZZ  Français établis hors de France                           8          8ème circonscription     Complet    130068  ...            F       LE PEN       Marine         3345         2.57        14.02
: 574                  ZZ  Français établis hors de France                           9          9ème circonscription     Complet    121013  ...            F       LE PEN       Marine         4988         4.12        13.28
: 575                  ZZ  Français établis hors de France                          10         10ème circonscription     Complet    104829  ...            F       LE PEN       Marine         8085         7.71        20.39
: 576                  ZZ  Français établis hors de France                          11         11ème circonscription     Complet     98707  ...            F       LE PEN       Marine         7246         7.34        18.88
:
: [5 rows x 33 columns]

#+begin_src python :session
df_2 = T2[['Nuls', 'Blancs', 'Abstentions']].copy()
df_2["Non exprimés"] =  df_2['Nuls'] + df_2['Blancs'] + df_2['Abstentions']
df_2 = df_2[["Non exprimés"]].copy()
T2['Code de la circonscription'] = T2['Code de la circonscription'].apply(str)
#df_1['circonscription'] = T1['Code du département'] + T1['Code de la circonscription']
df_2.head()
#+end_src

#+RESULTS:
:    Non exprimés
: 0         25547
: 1         28855
: 2         27496
: 3         27276
: 4         26071

#+begin_src python :session :results silent
col_start = 21
col_par_cdt = 7
candidats = T2.iloc[0][col_start::col_par_cdt]

for i_candidat, candidat in enumerate(candidats):
    i_col = col_start + i_candidat*col_par_cdt + 2
    print('# colonne', i_col, ' résultats=', T2.iloc[:, i_col].values)
    df_2[candidat] = T2.iloc[:, i_col].values
#+end_src

#+begin_src python :session :results file :exports both :var filename=(org-babel-temp-file "figure" ".png")
fig, ax = plt.subplots(figsize=(13, 5))
k = df_2.sum()/df_2.sum().sum()
ax = k.plot.bar(ax=ax)
ax.set_xlabel('Candidat')
ax.set_ylabel('pourcentage');
plt.savefig(filename, bbox_inches="tight")
filename
#+end_src

#+RESULTS:
[[file:/tmp/babel-XyHH31/figuremqqV6A.png]]

** Second order

#+begin_src python :session :results file :exports both :var filename=(org-babel-temp-file "figure" ".png")
import seaborn as sns

CDT_1 = "ARTHAUD"
CDT_2 = "LE PEN"

df_12 = pd.DataFrame()
df_12[CDT_1] = df_1[CDT_1].copy()
df_12[CDT_2] = df_2[CDT_2].copy()

df_12[CDT_1] = df_12[CDT_1]/df_1.sum(axis=1)
df_12[CDT_2] = df_12[CDT_2]/df_2.sum(axis=1)

fig = plt.figure()
sns.jointplot(x=df_12[CDT_1], y=df_12[CDT_2], kind='hist', height=8);
plt.savefig(filename)
filename
#+end_src

#+RESULTS:
[[file:/tmp/babel-XyHH31/figurepOF83v.png]]


#+begin_src python :session :results file :exports both :var filename=(org-babel-temp-file "figure" ".png")
import seaborn as sns

CDT_1 = "ARTHAUD"
CDT_2 = "Non exprimés"

df_12 = pd.DataFrame()
df_12[CDT_1] = df_1[CDT_1].copy()
df_12[CDT_2] = df_2[CDT_2].copy()

df_12[CDT_1] = df_12[CDT_1]/df_1.sum(axis=1)
df_12[CDT_2] = df_12[CDT_2]/df_2.sum(axis=1)

fig = plt.figure()
sns.jointplot(x=df_12[CDT_1], y=df_12[CDT_2], kind='hist', height=8);
plt.savefig(filename)
filename
#+end_src

#+RESULTS:
[[file:/tmp/babel-XyHH31/figuree61a2v.png]]

#+begin_src python :session :results file :exports both :var filename=(org-babel-temp-file "figure" ".png")
import seaborn as sns

CDT_1 = "POUTOU"
CDT_2 = "LE PEN"

df_12 = pd.DataFrame()
df_12[CDT_1] = df_1[CDT_1].copy()
df_12[CDT_2] = df_2[CDT_2].copy()

df_12[CDT_1] = df_12[CDT_1]/df_1.sum(axis=1)
df_12[CDT_2] = df_12[CDT_2]/df_2.sum(axis=1)

fig = plt.figure()
sns.jointplot(x=df_12[CDT_1], y=df_12[CDT_2], kind='hist', height=8);
plt.savefig(filename)
filename
#+end_src

#+RESULTS:
[[file:/tmp/babel-XyHH31/figurer9WIUm.png]]

* Simple modèle écologique



#+begin_src python :session :results silent
second = df_2[1:].values[:577, :]
premier = df_1[1:].values[:577:]
n_premier = premier.shape[1]
n_second = second.shape[1]
n_circos = premier.shape[0]
#+end_src

The model we implement is taken from [[https://gking.harvard.edu/files/em.pdf][this paper.]] We will be using =aesara= for modelling and =blackjax= for sampling.

** Simplified version (full mixing of the transition matrix)

#+begin_src python :session :results silent
import aesara.tensor as at
from aesara.tensor.random import RandomStream

srng = RandomStream(0)

p1_at = at.as_tensor(premier / premier.sum(axis=1).reshape((premier.shape[0], 1)))
beta_rv = srng.dirichlet(at.ones((n_premier, n_second)))
p2_at = at.dot(p1_at, beta_rv)
p2_at_norm = p2_at / p2_at.sum(axis=1).reshape((p2_at.shape[0], 1))
R2_rv = srng.multinomial(at.sum(second, axis=1), p2_at)
#+end_src

#+begin_src python :session :results silent
R2_vv = R2_rv.clone()
beta_vv = beta_rv.clone()

transforms_op = TransformValuesOpt(
     {beta_vv: SimplexTransform()}
)
logprob = joint_logprob(
    {R2_rv: R2_vv, beta_rv: beta_vv},
    extra_rewrites=transforms_op
)

# Compile the logprob function
logprob_fn = aesara.function((beta_vv, R2_vv), logprob)
#+end_src

#+begin_src python :session :results output
beta = SimplexTransform().forward(beta_rv).eval()
print(logprob_fn(beta, second))
#+end_src

#+RESULTS:

#+begin_src python :session
from aesara.link.jax.dispatch import jax_funcify
from aesara.graph.fg import FunctionGraph
from aeppl.opt import logprob_rewrites_db
from aesara.compile import mode
from aesara.raise_op import CheckAndRaise

@jax_funcify.register(CheckAndRaise)
def jax_funcify_Assert(op, **kwargs):
    # Jax does not allow assert whose values aren't known during JIT compilation
    # within it's JIT-ed code. Hence we need to make a simple pass through
    # version of the Assert Op.
    # https://github.com/google/jax/issues/2273#issuecomment-589098722
    def assert_fn(value, *inps):
        return value

    return assert_fn

fgraph = FunctionGraph(inputs=(beta_vv, R2_vv), outputs=(logprob,))
mode.JAX.optimizer.optimize(fgraph)
jax_fn = jax_funcify(fgraph)
#+end_src

#+RESULTS:

#+begin_src python :session :results output
M = SimplexTransform().forward(beta_rv).eval()
print(jax_fn(M, second)[0])
#+end_src

#+RESULTS:
: -2310109.6672252584

#+begin_src python :session
def logpdf(beta):
    return jax_fn(beta, second)[0]
#+end_src

#+RESULTS:

#+begin_src python :session :results silent
import jax
import blackjax


def inference_loop(rng_key, kernel, initial_state, num_samples):
    """Sequantially draws samples given the kernel of choice."""

    def one_step(state, rng_key):
        state, _ = kernel(rng_key, state)
        return state, state

    keys = jax.random.split(rng_key, num_samples)
    _, states = jax.lax.scan(one_step, initial_state, keys)

    return states


rng = jax.random.PRNGKey(0)
adapt = blackjax.window_adaptation(blackjax.nuts, logpdf, 3000, initial_step_size=1., target_acceptance_rate=0.8)
state, kernel, _ = adapt.run(rng, M)
samples = inference_loop(rng, kernel, state, 1000)
#+end_src

#+begin_src python :session
trans_at = at.matrix()
untrans_at = SimplexTransform().backward(trans_at)

fgraph = FunctionGraph(inputs=(trans_at,), outputs=(untrans_at,))
mode.JAX.optimizer.optimize(fgraph)
untransform_fn = jax_funcify(fgraph)
#+end_src

#+RESULTS:

#+begin_src python :session
a = jax.vmap(untransform_fn, in_axes=(0))(samples.position)[0]
jnp.mean(a, axis=0)
#+end_src

#+RESULTS:
|    0.878604297 |   0.0258612203 |   0.0955344828 |
| 0.000223786225 |  0.00017233535 |    0.999603878 |
|    0.353812974 | 0.000762828276 |    0.645424198 |
| 1.23942505e-05 |    0.999982994 |  4.6121251e-06 |
|    0.456609718 | 9.08177981e-05 |    0.543299464 |
|   4.226596e-06 | 3.34375375e-06 |     0.99999243 |
|    0.334170929 |    0.165825645 |    0.500003427 |
|    0.413016729 |    0.567315435 |   0.0196678352 |
| 0.000552152712 |     0.99932251 | 0.000125337773 |
| 4.11361658e-05 |    0.999943891 | 1.49731413e-05 |
|   0.0369822017 |    0.962924784 | 9.30145364e-05 |
|  0.00201357423 |   0.0014996482 |    0.996486778 |
| 9.11804856e-05 | 6.04221729e-05 |    0.999848397 |

#+begin_src python :session
jnp.std(a, axis=0)
#+end_src

#+RESULTS:
| 0.000512569718 | 0.000422569878 | 0.000411759099 |
| 0.000227764635 | 0.000163277737 | 0.000285016154 |
|  0.00835850634 |  0.00073835611 |  0.00834943886 |
| 1.17570106e-05 | 1.25917198e-05 | 4.70890492e-06 |
|  0.00365140492 | 8.73912586e-05 |  0.00365640129 |
| 4.43859768e-06 | 3.56362398e-06 | 5.91070475e-06 |
|  0.00381819399 |  0.00359687914 |  0.00259848234 |
|   0.0010802287 |  0.00095616888 | 0.000884318653 |
|  0.00056388714 | 0.000574331051 | 0.000130463264 |
| 3.99026341e-05 | 4.14860574e-05 | 1.49185181e-05 |
|  0.00503139143 |  0.00502770986 | 9.19645282e-05 |
|   0.0019754635 |  0.00158481525 |  0.00251857998 |
| 8.87382366e-05 |  6.1380908e-05 | 0.000105200007 |

On vérifie que le modèle, aussi surprenant que cela soit, est k

#+begin_src python :session
a[:, 1, 2][:100]
#+end_src

#+RESULTS:
| 0.99962791 | 0.99991623 | 0.99966305 | 0.99946064 | 0.99938046 | 0.99937188 | 0.99980659 | 0.999792 | 0.99923505 | 0.99953717 | 0.99951034 | 0.99959796 | 0.99957745 | 0.99986323 | 0.99975899 | 0.9996055 | 0.99928098 | 0.99986385 | 0.99988614 | 0.99984921 | 0.99942679 | 0.99886797 | 0.99980025 | 0.9995409 | 0.99961997 | 0.99944473 | 0.99943799 | 0.99949746 | 0.99953126 | 0.99979873 | 0.99968739 | 0.99986479 | 0.99959014 | 0.99985252 | 0.99920973 | 0.99971285 | 0.99979184 | 0.99950867 | 0.99925911 | 0.99948833 | 0.99949589 | 0.9996224 | 0.99961641 | 0.99974562 | 0.99960092 | 0.99979708 | 0.99991249 | 0.99940249 | 0.99975145 | 0.99934725 | 0.99997605 | 0.99810388 | 0.99983037 | 0.99966022 | 0.99944754 | 0.99954732 | 0.99942889 | 0.99945266 | 0.99898081 | 0.99995676 | 0.9999735 | 0.99997122 | 0.99996205 | 0.99800344 | 0.99998724 | 0.99987909 | 0.99979481 | 0.99981912 | 0.9998331 | 0.99980382 | 0.99970231 | 0.99978394 | 0.99973909 | 0.99961615 | 0.99966534 | 0.99957562 | 0.99971179 | 0.99955648 | 0.99947529 | 0.99900012 | 0.99977318 | 0.99986157 | 0.99981946 | 0.99949235 | 0.99975582 | 0.99978152 | 0.99940828 | 0.99943139 | 0.99903068 | 0.99912911 | 0.99981919 | 0.99974803 | 0.99903316 | 0.99971128 | 0.99949675 | 0.9996083 | 0.99977729 | 0.99960927 | 0.99948289 | 0.99941847 |

** Hyperprior on dirichlet

#+begin_src python :session :results silent
second = df_2[1:].values[:100,:]
premier = df_1[1:].values[:100,:]
n_premier = premier.shape[1]
n_second = second.shape[1]
n_circos = premier.shape[0]
#+end_src

#+begin_src python :session :results silent
import aesara.tensor as at
from aesara.tensor.random import RandomStream

srng = RandomStream(0)

p1_at = at.as_tensor(premier / premier.sum(axis=1).reshape((premier.shape[0], 1)))
delta_rv = srng.exponential(at.ones((n_premier, n_second)) * 10.)
beta_rv = srng.dirichlet(delta_rv)
p2_at = at.dot(p1_at, beta_rv)
p2_at_norm = p2_at / p2_at.sum(axis=1).reshape((p2_at.shape[0], 1))
R2_rv = srng.multinomial(at.sum(second, axis=1), p2_at)
#+end_src

#+begin_src python :session :results silent
from aeppl.transforms import TransformValuesOpt, LogTransform, SimplexTransform


R2_vv = R2_rv.clone()
beta_vv = beta_rv.clone()
delta_vv = delta_rv.clone()

transforms_op = TransformValuesOpt(
     {beta_vv: SimplexTransform(), delta_vv: LogTransform()}
)
logprob = joint_logprob(
    {R2_rv: R2_vv, beta_rv: beta_vv, delta_rv: delta_vv},
    extra_rewrites=transforms_op
)

# Compile the logprob function
logprob_fn = aesara.function((beta_vv, delta_vv, R2_vv), logprob)
#+end_src

#+begin_src python :session :results output
beta = SimplexTransform().forward(beta_rv).eval()
delta = LogTransform().forward(delta_rv).eval()
print(logprob_fn(beta, delta, second))
#+end_src

#+RESULTS:

#+begin_src python :session
from aesara.link.jax.dispatch import jax_funcify
from aesara.graph.fg import FunctionGraph
from aeppl.opt import logprob_rewrites_db
from aesara.compile import mode
from aesara.raise_op import CheckAndRaise

@jax_funcify.register(CheckAndRaise)
def jax_funcify_Assert(op, **kwargs):
    # Jax does not allow assert whose values aren't known during JIT compilation
    # within it's JIT-ed code. Hence we need to make a simple pass through
    # version of the Assert Op.
    # https://github.com/google/jax/issues/2273#issuecomment-589098722
    def assert_fn(value, *inps):
        return value

    return assert_fn

fgraph = FunctionGraph(inputs=(beta_vv, delta_vv, R2_vv), outputs=(logprob,))
mode.JAX.optimizer.optimize(fgraph)
jax_fn = jax_funcify(fgraph)
#+end_src

#+RESULTS:

#+begin_src python :session :results output
M = SimplexTransform().forward(beta_rv).eval()
d = LogTransform().forward(delta_rv).eval()
print(jax_fn(M, d, second)[0])
#+end_src

#+RESULTS:
: -325017.85796774126

#+begin_src python :session
def logpdf(x):
    beta, delta = x
    return jax_fn(beta, delta, second)[0]
#+end_src

#+RESULTS:

#+begin_src python :session :results silent
import jax
import blackjax


def inference_loop(rng_key, kernel, initial_state, num_samples):
    """Sequantially draws samples given the kernel of choice."""

    def one_step(state, rng_key):
        state, _ = kernel(rng_key, state)
        return state, state

    keys = jax.random.split(rng_key, num_samples)
    _, states = jax.lax.scan(one_step, initial_state, keys)

    return states


rng = jax.random.PRNGKey(0)
adapt = blackjax.window_adaptation(blackjax.nuts, logpdf, 3000, initial_step_size=1., target_acceptance_rate=0.8)
state, kernel, _ = adapt.run(rng, (M, d))
samples = inference_loop(rng, kernel, state, 1000)
#+end_src

#+begin_src python :session
trans_at = at.matrix()
untrans_at = LogTransform().backward(trans_at)

fgraph = FunctionGraph(inputs=(trans_at,), outputs=(untrans_at,))
mode.JAX.optimizer.optimize(fgraph)
untransform_fn = jax_funcify(fgraph)
#+end_src

#+RESULTS:

#+begin_src python :session
a = jax.vmap(untransform_fn, in_axes=(0))(samples.position[1])[0]
jnp.mean(a, axis=0)
#+end_src

#+RESULTS:
| 29.60603574 |  2.34199847 |  2.98394168 |
|  0.44175271 |  0.31861708 | 18.08521358 |
|  14.2330665 |   0.4175809 | 16.53486333 |
|  0.14939946 | 13.42957026 |  0.16539151 |
| 10.85680003 |  0.13078875 | 11.67389942 |
|   0.0426811 |  0.14017083 | 11.50171714 |
|  3.61469926 |  0.94584796 | 23.13918023 |
|   8.4651884 | 14.49454873 |  0.18589097 |
| 18.55727688 |  4.93651698 |  0.21684371 |
|  0.19961832 | 11.31421649 |  0.11511398 |
|  2.14471167 |  17.3388221 |   0.3826252 |
|  1.08048987 |   0.3547419 | 18.32616482 |
|  0.34198671 |  0.24493664 | 15.64597391 |

#+begin_src python :session
jnp.std(a, axis=0)
#+end_src

#+RESULTS:
| 2.22044605e-16 | 1.38777878e-17 | 3.33066907e-16 |
| 7.77156117e-16 | 2.77555756e-17 | 2.77555756e-17 |
| 6.31088724e-30 | 5.55111512e-17 | 1.11022302e-16 |
| 1.05879118e-22 | 6.66133815e-16 | 1.11022302e-16 |
| 5.95570041e-23 | 2.11758237e-22 | 5.55111512e-16 |
| 1.48230766e-21 | 9.99200722e-16 | 9.71445147e-17 |
| 5.55111512e-16 | 5.22024357e-53 | 1.04083409e-17 |
|  4.7433845e-20 |            0.0 | 1.11022302e-16 |
|            0.0 | 2.22044605e-16 | 4.06575815e-20 |
| 3.33066907e-16 |            0.0 | 3.33066907e-16 |
|            0.0 | 7.57306469e-29 |            0.0 |
|  6.6174449e-24 | 3.33066907e-16 | 8.47032947e-22 |
| 6.24500451e-17 | 5.55111512e-16 |            0.0 |

Les résultats sont de toute évidence faux: il suffit de comparer les graphes avec les statistiques de second ordre plus haut et les valeurs que l'on obtient pour les priors des distributions des lignes de la matrice de transition. Pour comprendre ce qui se passe il va falloir retourner au tableau, et notamment regarder les /prior predictive distributions/ pour les matrices de transition et voir si elles permettent de retrouver les courbes X au premier tour vs Y au second tour. Trois hypothèses:

- La paramétrisation du modèle est mauvaise;
- L'impact des variations de la logprob correspondants aux petit candidats est tellement faible que le modèle est surtout déterminé par la valeur a priori. On peut alors soit prendre un sondage pour les valeurs a priori, soit les "fabriquer".
- Le modèle hiérarchique est nécessaire. Un moyen de voir si cela va changer quelque chose est de fitter ce modèle sur une seule circonscription.
